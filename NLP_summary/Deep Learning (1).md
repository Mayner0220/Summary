# Deep Learning (1)

Source: https://wikidocs.net/22882, https://wikidocs.net/24958, https://wikidocs.net/24987, https://wikidocs.net/36033, https://wikidocs.net/37406, https://wikidocs.net/61374, https://wikidocs.net/61375, https://wikidocs.net/32105, https://wikidocs.net/38861, https://wikidocs.net/49071, https://wikidocs.net/45609

---

### 0. 딥 러닝(Deep Learning) 개요

DL이 화두가 되고 있는 것은 비교적 최근의 일이지만, DL의 기본 구조인 인공 신경망(Artificial Neural Network)의 역사는 생각보다 오래되었다.
DL을 손쉽게 이해하기 위해서 1957년에 등장한 초기 인공 신경망부터 학습해보자.
초기 신경망인 퍼셉트로(Perceptron)부터 피드 포워드 신경망 언어 모델의 정의 그리고 기본적인 케라스의 사용법에 대해서 배워보자.

---

### 1. 퍼셉트론(Perceptron)

인공 신경망은 수많은 ML 방법 중 하나이다.
하지만 최근 인공 신경망을 복잡하게 쌓아 올린 DL이 다른 ML 방법들을 뛰어넘는 성능을 보여주는 사례가 늘면서, 전통적인 ML과 DL을 구분해서 이해해야 한다는 목소리가 커지고 있다.
DL을 이해하기 위해서  우선 인공 신경망에 대한 이해가 필요한데, 초기의 인공 신경망인 퍼셉트론에 대해서 이해하자.

---

### 1.1 퍼셉트론

퍼셉트론은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘이다.
퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 먼저 보도록 하자.
뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달한다.

![img](https://wikidocs.net/images/page/24958/%EB%89%B4%EB%9F%B0.PNG)

이제 다수의 입력을 받는 퍼셉트론의 그리을 보자.
신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당된다.

![img](https://wikidocs.net/images/page/24958/perceptrin1_final.PNG)

x는 입력값을 의미하며, W는 가중치(weight), y는 출력값이다.
그림 안의 원은 인공 뉴런에 해당된다.
실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치자 대신한다.
각각의 인공 뉴런에서 보내진 입력값 x는 각각의 가중치 W와 함께 종착지인 인공 뉴런에 전달되고 있다.

각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미한다.

각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력한다.
이러한 함수를 계단 함수(Step function)라고 하며, 아래의 그래프는 계단 함수의 하나의 예를 보여준다.

![img](https://wikidocs.net/images/page/24987/step_function.PNG)

이때 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현한다.
이를 식으로 표현하면 다음과 같다.
$$
if \sum_i^{n} W_{i}x_{i}\ ≥ \theta → y=1
$$

$$
if \sum_i^{n} W_{i}x_{i}\ < \theta → y=0
$$

단, 위의 식에서 임계치를 좌변으로 넘기고 편향 b(bias)로 표현할 수도 있다.
편향 b 또한 퍼셉트론의 입력으로 사용된다.
보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 b가 곱해지는 변수로 표현된다.

![img](https://wikidocs.net/images/page/24958/perceptron2_final.PNG)
$$
if \sum_i^{n} W_{i}x_{i} + b ≥ 0 → y=1
$$

$$
if \sum_i^{n} W_{i}x_{i} + b < 0 → y=0
$$

많은 인공 신경망 자료에서 편의상 편향 b가 그림이나 수식에서 생략되서 표현되기도 하지만 실제로는 편향 b 또한 DL이 최적의 값을 찾아야 할 변수 중 하나이다.

이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 한다.
초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용하였지만, 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했다.
사실 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나이다.

페셉트론 배우기 전에 로지스틱 회귀를 먼저 배운 이유도 여기에 있다.
퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있다.

다시 말하면 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있다.
로지스틱 회귀를 수행하는 인공 뉴런과 위에서 배운 퍼셉트론의 차이는 오직 활성화 함수의 차이이다.

- 인공 뉴런: 활성화 함수
  $$
  f(\sum_i^{n} W_{i}x_{i} + b)
  $$

- 위의 퍼셉트론: 계단 함수
  $$
  f(\sum_i^{n} W_{i}x_{i} + b)
  $$
  

---

### 1.2 단층 퍼셉트론(Single-Layer Perceptron)

위에서 배운 퍼셉트론을 단층 퍼셉트론이라고 한다.
퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어지는데, 단층 퍼셉트론은 값을 보내는 단계와 값을 받아서 출력하는 두 단계로만 이루어진다.
이떄 이 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)이라고 한다.

![img](https://wikidocs.net/images/page/24958/perceptron3_final.PNG)

단층 퍼셉트론의 한계를 개선하기 위해 항후에 나온 다층 퍼셉트론을 배우게 되면 단층과 다층 이 두 퍼셉트론이 어떤 차이를 가지는지 쉽게 이해할 수 있다.
단층 퍼셉트론이 어떤 일을 할 수 있으며 한계는 무엇인지 학습해보자..

단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있다.
게이트 연산에 쓰이는 것은 두 개의 입력값과 출력값이다.
예를 들어 AND 게이트의 경우에는 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 갖고 있다.

![img](https://wikidocs.net/images/page/24958/andgate.PNG)

단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까.
각각 w1, w2, b라고 한다면 [0.5, 0.5, -0.7], [0.5, 0.5, -0.8] 또는 [1.0, 1.0, -1.0] 등 이 외에도 다양한 가중치와 편향의 조합이 나올 수 있다.
이해를 돕기 위해서 AND 게이트를 위한 매개변수 값을 가진 단층 퍼셉트론의 식을 파이썬 코드로 간단하게 구현해보자.

```python
def AND_gate(x1, x2):
    w1=0.5
    w2=0.5
    b=-0.7
    result = x1*w1 + x2*w2 + b
    if result <= 0:
        return 0
    else:
        return 1
```

위의 함수에 AND 게이트의 입력값을 모두 넣어보면 오직 두 개의 입력값이 1인 경우에만 1을 출력한다.

```python
AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)
```

```python
(0, 0, 0, 1)
```

그렇다면 두 개의 입력값이 1인 경우에만 출력값이 0, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이 나오는 NAND 게이트는 어떨까.

![img](https://wikidocs.net/images/page/24958/nandgate.PNG)

앞서 언급했던 AND 게이트를 충족하는 가중치와 편향값인 [0.5, 0.5, -0.7]에 -를 붙여서 [-0.5, -0.5, +0.7]을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족한다.
파이썬 코드를 통해서 이를 확인해보자.

```python
def NAND_gate(x1, x2):
    w1=-0.5
    w2=-0.5
    b=0.7
    result = x1*w1 + x2*w2 + b
    if result <= 0:
        return 0
    else:
        return 1
```

단지 같은 코드에 함수 이름과 가중치와 편향만 바뀌었을 뿐이다.
퍼셉트론의 구조는 같기 때문이다.

```python
NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)
```

```python
(1, 1, 1, 0)
```

NAND 게이트를 구현한 파이썬 코드에 입력값을 넣자, 두 개의 입력값이 1인 경우에만 0이 나오는 것을 확인할 수 있다.
퍼셉트론으로 NAND 게이트를 구현한 것이다.
[-0.5, -0.5, -0.7] 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것 이다.

두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있다.

![img](https://wikidocs.net/images/page/24958/orgate.PNG)

예를 들어 각각 가중치와 편향에 대해서 [0.6, 0.6, -0.5]를 선택하면 OR 게이트를 충족한다.

```python
def OR_gate(x1, x2):
    w1=0.6
    w2=0.6
    b=-0.5
    result = x1*w1 + x2*w2 + b
    if result <= 0:
        return 0
    else:
        return 1
```

```python
OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)
```

```python
(0, 1, 1, 1)
```

물론, 이 외에도 이를 충족하는 다양한 가중치와 편향의 값이 있다.

이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있다.
하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 XOR 게이트이다.
XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을 때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트 이다.
위의 파이썬 코드에 아무리 수 많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능하다.
그 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문이다.

예를 들어 AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같다.

![img](https://wikidocs.net/images/page/24958/andgraphgate.PNG)

그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했다.
AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 된다.
마찬가지로 NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능하다.

![img](https://wikidocs.net/images/page/24958/oragateandnandgate.PNG)

그렇다면 XOR 게이트는 어떨까.
XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트이다.
XOR 게이트를 시각화해보면 다음과 같다.

![img](https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG)

하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능하다.
즉, 단층 퍼셉틍론으로는 XOR 게이트를 구현하는 것이 불가능하다.
이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말한다.
다시 말하면 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능하다.

![img](https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG)

위의 그림은 곡선을 사용한다면 하얀색 원과 검은색 원을 나눌 수 있음을 보여준다.
이제 XOR 게이트를 만들 수 있는 다층 퍼셉트론에 대해서 알아보도록 하자.

---

### 1.3 다층 퍼셉트론(Multi-Layer Perceptron, MLP)

XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있다.
퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있다.
다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점이다.
이렇게 입력층과 출력층 사이에 존재하는 층을 은닉층(hidden layer)이라고 한다.
즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다르다.
다층 퍼셉트론은 줄여서 MLP라고도 부른다.

![img](https://wikidocs.net/images/page/24958/perceptron_4image.jpg)

위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다중 퍼셉트론의 예이다.
XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말한다.
즉, XOR 문제보다 더욱 복잡한 문제를 해결하기위해서 다층 퍼셉트론은 중간에 수 많은 은닉층을 더 추가할 수 있다.
은닉층의 개수는 2개일 수도 있고, 수십 개일 수도 있고 사용자가 설명하기 나름이다.
아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고, 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여준다.

![img](https://wikidocs.net/images/page/24958/%EC%9E%85%EC%9D%80%EC%B8%B5.PNG)

위와 같이 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 한다.
심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 한다.

지금까지는 OR, AND, XOR 게이트 등. 퍼셉트론이 가야할 정답을 참고로 퍼셉트론이 정답을 출력할 때까지 가중치를 바꿔보면서 맞는 가중치를 찾았다.
즉, 가중치를 수동으로 찾았다.
하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 학습(training) 단계에 해당된다.
앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용한다.
그리고 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, 딥 러닝(Deep Learning)이라고 한다.

---

### 2. 인공 신경망(Artificial Neural Network) 훑어보기

이번에는 인공 신경망에 대한 전반적인 정리한다.

---

### 2.1 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)

![img](https://wikidocs.net/images/page/24987/mlp_final.PNG)

위의 다층 퍼셉트론(MLP)과 같이 입력층에서 출력층 방향으로 연산이 전개되는 신경망을 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)이라고 한다.
이렇게 별도로 정의되는 이유는 FFNN이 아닌 신경망이 존재하기 때문이다.

![img](https://wikidocs.net/images/page/24987/rnn_final.PNG)

위의 그림은 대표적으로 FFNN이 아닌 RNN이라는 신경망을 보여준다.
이 신경망은 은닉층의 출력값을 출력층으로도 값을 보내지만, 동시에 은닉층의 출력값이 다시 은닉층의 입력으로 사용되는데 이는 FFNN의 정의에 벗어난다.
이는 RNN 챕터에서 학습한다.

---

### 2.2 전결합층(Fully-connected layer, FC, Dense layer)

앞서 본 다층 퍼셉트론은 은닉층과 출력층에 있는 모든 뉴런은 바로 이전 층의 모든 뉴런과 연결되어있었다.
그와 같이 어떤 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결되어있는 층을 전결합층이라고 한다.
줄여서 FC라고 부르기도 한다.

즉, 앞서 본 다층 퍼셉트론의 모든 은닉층과 출력층은 전결합층이다.
이와 동일한 의미로 밀집층(Dense Layer)이라고 부르기도 하는데, 케라스에서는 밀집층을 구현할 때 Dense()를 사용한다.
자세한 구현 방법은 뒤에서 배운다.

만약 전결합층만으로 구성된 피드 포워드 신경망이 있다면, 이를 전결합 피드 포워드 신경망(Fully-connected FFNN)이라고도 한다.

---

### 2.3 활성화 함수(Activation Function)

![img](https://wikidocs.net/images/page/24987/activation_function_final.PNG)

앞서 배운 퍼셉트론에서는 계단 함수(Step function)를 통해 출력값이 0이 될지, 1이 될지를 결정한다.
이러한 매커니즘은 실제 뇌를 구성하는 신경 세포 뉴런이 전위가 일정치 이상이 되면 시냅스가 서로 화학적으로 연결되는 모습을 모방한 것이다.
이렇게 은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수를 활성화 함수(Activation function)라고 하는데 계단 함수는 이러한 활성화 함수의 하나의 예제에 불과한다.

1. 활성화 함수의 특징 - 비선형 함수(Nonlinear function)
   활성화 함수의 특징은 선형 함수가 아닌 비선형 함수여야 한다는 점이다.
   선형 함수란 출력이 입력의 상수배만큼 변하는 함수를 선형함수라고 한다.
   예를 들어 f(x)=Wx+b라는 함수가 있을 때, W와 b는 상수이다.
   이 식은 그래프를 그리면 직선이 그려진다.
   반대로 비선향 함수는 직선 1개로는 그릴 수 없는 함수를 말한다.

   인공 신경망에서 활성화 함수는 반드시 비선형 함수여야 한다.
   앞서 퍼셉트론에서도 계단 함수라는 활성화 함수를 사용했다.
   즉, 계단 함수 또한 비선형 함수에 속합니다.

   인공 신경망의 능력을 높이기 위해서는 은닉층을 계속해서 추가해야 한다.
   그런데 만약 활성화 함수로 선형 함수를 사용하게 되면 은닉층을 쌓을 수가 없다.
   예를 들어 활성화 함수로 선형 함수를 선택하고, 층을 계속 쌓는다고 가정해보자.
   활성화 함구는 f(x)=Wx라고 가정하자.
   여기다가 은닉층을 두 개 추가한다고하면 출력층을 포함해서 y(x)=f(f(f(x)))가 된다.
   이를 식으로 표현하면 W * W * W * x이다.
   그런데 이는 잘 생각해보면 W의 세 제곱값을 k라고 정의해버리면 y(x) = kx와 같이 다시 표현이 가능하다.
   즉, 선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없다.

   선형 함수를 사용한 은닉층을 1회 추가한 것과 연속으로 추가한 것과 연속으로 추가한 것이 차이가 없다는 뜻이며, 선형 함수를 사용한 층이 아무 의미가 없다는 뜻이 아니다.
   학습 가능한 가중치가 새로 생긴다는 점에서 분명히 의미가 있다.
   이와 같이 선형 함수를 사용한 층을 활성화 함수를 사용하는 은닉층과 구분하기 위해서 선형층(linear layer)이나 투사층(projection layer) 등의 다른 표현을 사용하여 표현하기도 한다.
   활성화 함수를 사용하는 일반적인 은닉층을 선형층과 대비되는 표현을 사용하면 비선형층(nonlinear layer)이다.

   파이썬을 통해 주로 사용되는 활성화 함수를 직접 그려보고, 이해해보도록 하겠다.
   아래의 모든 코드는 앞서 아래의 코드가 먼저 수행되었다고 가정하자.

   ```python
   import numpy as np # 넘파이 사용
   import matplotlib.pyplot as plt # 맷플롯립 사용
   ```

2. 계단 함수(Step function)

   ![img](https://wikidocs.net/images/page/24987/step_function.PNG)

   ```python
   def step(x):
       return np.array(x > 0, dtype=np.int)
   x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성
   y = step(x)
   plt.title('Step Function')
   plt.plot(x,y)
   plt.show()
   ```

   계단 함수는 이제 거의 사용되지 않지만, 퍼셉트론을 통해 처음으로 인공 신경망을 배울 때 가장 처음 접하게 되는 활성화 함수이다.

3. 시그모이드 함수(Sigmoid function)와 기울기 소실
   시그모이드 함수를 사용한 어떤 인공 신경망이 있다고 가정해보자.

   ![img](https://wikidocs.net/images/page/60683/simple-neural-network.png)

   위 인공 신경망의 학습 과정은 다음과 같다.
   우선 인공 신경망은 입력에 대해서 순전파(forward propagation) 연산 하고, 그리고 순전파 연산를 통해 나온 예측값과 실제값의 오차를 손실 함수(loss function)을 통해 계산하고, 그리고 이 손실(loss)을 미분을 통해서 기울기(gradient)를 구하고, 이를 통해 역전파(back propagation)를 수행한다.

   그리고 시그모이드 함수의 문제점은 미분을 해서 기울기(gradient)를 구할 때 발생합니다.

   ```python
   # 시그모이드 함수 그래프를 그리는 코드
   def sigmoid(x):
       return 1/(1+np.exp(-x))
   x = np.arange(-5.0, 5.0, 0.1)
   y = sigmoid(x)
   
   plt.plot(x, y)
   plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
   plt.title('Sigmoid Function')
   plt.show()
   ```

   ![img](https://wikidocs.net/images/page/60683/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%ED%95%A8%EC%88%981.PNG)

   위의 그래프는 시그모이드 함수의 그래프를 보여준다.
   위 그래프를 시그모이드 함수의 출력값이 0 또는 1에 가까워지면, 그래프의 기울기가 완만해지는 모습을 볼 수 있다.
   기울기가 왠만해지는 구간을 주황색, 그렇지 않은 구간을 초록색으로 칠해보자.

   ![img](https://wikidocs.net/images/page/60683/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%ED%95%A8%EC%88%982.PNG)

   주황색 부분은 기울기를 계산하면 0에 가까운 아주 작은 값이 나오게 된다.
   그런데 역전파 과정에서 0에 가까운 아주 작은 기울기가 곱해지면, 앞단에는 기울기가 잘 전달되지 않게 된다.
   이러한 현상을 기울기 소실(Vanishing Gradient) 문제라고 한다.

   시그모이드 함수를 사용하는 은닉층의 개수가 다수가 될 경우에는 0에 가까운 기울기가 계속 곱해지면 앞단에서는 거의 기울기를 전파받을 수 없게 된다.
   다시 말해 매개변수 W가 업데이트 되지 않아 학습이 되지를 않는다.

   ![img](https://wikidocs.net/images/page/60683/%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EC%86%8C%EC%8B%A4.png)

   위의 그림은 은닉층이 깊은 신경망에서 기울기 소실 문제로 인해 출력층과 가까운 은닉층에서는 기울기가 잘 전파되지만, 앞단으로 갈 수록 기울기가 제대로 전파되지 않는 모습을 보여준다.
   결론적으로 시그모이드 함수를 은닉층에서 사용하는 것은 지양된다.

4. 하이퍼볼릭탄젠트 함수(Hyperbolic tangent function)
   하이퍼볼릭탄젠트 함수(tanh)는 입력값을 -1과 1사이의 값으로 변환한다.
   그래프를 그려보자.

   ```python
   x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성
   y = np.tanh(x)
   
   plt.plot(x, y)
   plt.plot([0,0],[1.0,-1.0], ':')
   plt.axhline(y=0, color='orange', linestyle='--')
   plt.title('Tanh Function')
   plt.show()
   ```

   ![img](https://wikidocs.net/images/page/60683/%ED%95%98%EC%9D%B4%ED%8D%BC%EB%B3%BC%EB%A6%AD%ED%83%84%EC%A0%A0%ED%8A%B8.PNG)

   하이퍼볼릭탄젠트 함수도 -1과 1에 가까운 출력값을 출력할 때, 시그모이드 함수와 같은 문제가 발생한다.
   그러나 하이퍼볼릭탄젠트 함수의 경우에는 시그모이드 함수와는 달리 0을 중심으로 하고 있는데, 이 때문에 시그모이드 함수와 비교하면 반환값의 변화폭이 더 크다.
   그래서 시그모이드 함수보다는 기울기 소실 증상이 적은 편이다.
   그래서 은닉층에서 시그모이드 함수보다는 많이 사용한다.

5. 렐루 함수(ReLU)
   인공 신경망에서 가장 최고의 인기를 얻고 있는 함수입니다.
   수식은 
   $$
   f(x) = max(0, x)
   $$
   로 아주 간단하다.

   ```python
   def relu(x):
       return np.maximum(0, x)
   
   x = np.arange(-5.0, 5.0, 0.1)
   y = relu(x)
   
   plt.plot(x, y)
   plt.plot([0,0],[5.0,0.0], ':')
   plt.title('Relu Function')
   plt.show()
   ```

   ![img](https://wikidocs.net/images/page/60683/%EB%A0%90%EB%A3%A8%ED%95%A8%EC%88%98.PNG)

   렐루 함수는 음수를 입력하면 0을 출력하고, 양수를 입력하면 입력값을 그대로 반환한다.
   렐루 함수는 특정 양수값에 수렴하지 않으므로 깊은 신경망에서 시그모이드 함수보다 훨씬 더 잘 작동한다.
   뿐만 아니라, 렐루 함수 시그모이드 함수와 하이퍼볼릭탄젠트 함수와 같이 어떤 연산이 필요한 것이 아니라 단순 임계값이므로 연산 속도도 빠르다.

   하지만 여전히 문제점이 존재하는데, 입력값이 음수면 기울기도 0이된다.
   그리고 이 뉴런은 다시 회생하는 것이 매우 어렵다.
   이 문제를 죽은 렐루(dying ReLU)라고 한다.

6. 리키 렐루(Leaky ReLU)
   죽은 렐루를 보완하기 위해 ReLU의 변형 함수들이 등장하기 시작했다.
   변형 함수는 여러 개가 있지만 여기서는 Leaky ReLU에 대해서만 소개한다.
   Leaky ReLU는 입력값이 음수일 경우에 0이 아니라 0.001과 같은 매우 작은 수를 반환하도록 되어있다.

   수식 f(x)=max(ax, x)로 아주 간단하다.
   a는 하이퍼파라미터로 Leaky('새는') 정도를 결정하며 일반적으로 0.01의 값을 가진다.
   여기서 말하는 '새는 정도'라는 것은 입력값의 음수일 때의 기울기를 비유하고 있다.

   ```python
   a = 0.1
   ```

   ```python
   def leaky_relu(x):
       return np.maximum(a*x, x)
   
   x = np.arange(-5.0, 5.0, 0.1)
   y = leaky_relu(x)
   
   plt.plot(x, y)
   plt.plot([0,0],[5.0,0.0], ':')
   plt.title('Leaky ReLU Function')
   plt.show()
   ```

   ![img](https://wikidocs.net/images/page/60683/%EB%A6%AC%ED%82%A4%EB%A0%90%EB%A3%A8.PNG)

   위의 그래프에서는 새는 모습을 확실히 보여주기 위해 a를 0.1로 잡았다.
   위와 같이 입력값이 음수라도 기울기가 0이 되지 않으면 ReLU는 죽지 않는다.

7. 소프트맥스 함수(Softmax function)
   은닉층에서 ReLU(또는 ReLU 변형 함수) 함수들을 사용하는 것이 일반적이지만 그렇다고 해서 앞서 배운 시그모이드 함수나 소프트맥스 함수가 사용되지 않는다는 의미는 아니다.
   분류 문제를 로지스틱 회귀와 소프트맥스 회귀를 출력층에 적용하여 사용한다.

   ```python
   x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격 생성
   y = np.exp(x) / np.sum(np.exp(x))
   
   plt.plot(x, y)
   plt.title('Softmax Function')
   plt.show()
   ```

   ![img](https://wikidocs.net/images/page/60683/%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4.PNG)

   소프트맥스 함수는 시그모이드 함수처럼 출력층의 뉴런에서 주로 사용되는데, 시그모이드 함수가 두 가지 선택지 중 하나를 고르는 이진 분류(Binary Classification) 문제에 사용된다면 세 가지 이상의 (상호 베타적인) 선택지 중 하나를 고르는 다중 클래스 분류(Multi-Class Classification) 문제에 주로 사용된다.

---

### 2.4 행렬의 곱셈을 이용한 순전파(Forward Propagation)

![img](https://wikidocs.net/images/page/24987/neuralnetwork_final.PNG)

위와 같은 인공 신경망이 있다고 하자.
주어진 인공 신경망을 케라스로 구현해본다면 아래와 같이 짧은 코드로 구현할 수 있다.

```python
from keras.models import Sequential
from keras.layers import Dense
model = Sequential() # 층을 추가할 준비
model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))
# 입력층(4)과 다음 은닉층(8) 그리고 은닉층의 활성화 함수는 relu
model.add(Dense(8, activation='relu')) # 은닉층(8)의 활성화 함수는 relu
model.add(Dense(3, activation='softmax')) # 출력층(3)의 활성화 함수는 softmax
```

아직 케라스로 인공 신경망 모델을 만드는 방법을 자세히 배우지 않았지만, 사실 위의 코드가 어떤 의미인지 파악하는 것은 어렵지 않다.
위의 코드의 주석에서 () 괄호 안의 값은 각 층에서의 뉴런의 수를 의미하며 입력층부터 출력층까지 순차적으로 인공 신경망의 층을 한 층씩 추가했다.
케라스를 사용하면 이렇게 간단하게 DL 모델을 구현할 수 있다.

인공 신경망에서 입력층에서 출력층 방향으로 연산을 진행하는 과정을 순전파(Forward Propagation)라고 한다.
다르게 말하면 주어진 입력으로부터 예측값을 계산하는 과정을 순전파라고 한다.
앞서 머신 러닝 챕터에서 배웠던 벡터와 행렬 연산을 인공 신경망에 적용하려고 하면, 벡터와 행렬 연산이 순전파 과정에서 층(layer)마다 적용이 된다.

사실 케라스로 인공 신경망을 만들면 이러한 연산 과정을 자세히 이해하지 않아도 모델을 만들 수는 있지만, Numpy 등을 통해 인공 신경망을 로우 레벨로 개발하고 있다면 인공 신경망 내부 연산에 사용하는 행렬 크기를 고려해야 인공 신경망을 구현할 수 있다.
그렇기 때문에 비록 이 책은 케라스를 사용하지만, 적어도 로우 레벨 단계에서는 행렬의 크기가 어떻게 결정되는지 이해해보고자 한다.

1. layer 1의 행렬 크기 추정하기
   우선 각 층을 기준으로 입력과 출력의 개수를 정리하면 다음과 같다.

   - 입력층: 4개의 입력과 8개의 출력
   - 은닉층1: 8개의 입력과 8개의 출력
   - 은닉층2: 8개의 입력과 3개의 출력
   - 출력층: 3개의 입력과 3개의 출력

   여기서는 편의상 입력층을 layer 0, 은닉층 1을 layer 1, 은닉층 2를 layer 2, 출력층을 layer 3라고 해보자.
   이제 위의 정보를 가지고 층마다 생기는 가중치와 편향 행렬의 크기를 추정해보자.
   벡터와 행렬 연산 챕터에서 언급하였듯이 가중치 행렬에 입력 행렬을 곱하는 경우와 입력 행렬에 가중치 행렬을 곱하는 경우가 있겠으나, 여기서는 후자를 가정한다.
   또한 배치 크기는 1로 합니다. 이 경우 layer 1에서 처음 입력으로 들어오는 입력 행렬 XX의 크기는 1 × 41 × 4로 행벡터에 해당된다. 
   (만약 미니 배치 학습을 가정할 경우, X의 크기는 배치의 크기 × 4가 됩니다.)
   $$
   X_{m\ \text{×}\ n} × W_{n\ \text{×}\ j} + B_{m\ \text{×}\ j} = Y_{m\ \text{×}\ j}
   $$
   layer 1의 입력 행렬 X의 크기는 1 x 4이다.
   layer 1의 출력은 8개이므로, 그에 따라 출력 행렬 Y의 크기 1 x 8이 된다.

   
   $$
   X_{1\ \text{×}\ 4} × W_{n\ \text{×}\ j} + B_{m\ \text{×}\ j} = Y_{1\ \text{×}\ 8}
   $$
   그런데 가중치 행렬 W의 행은 입력 행렬 X의 열과 같아야 하므로 아래와 같다.
   $$
   X_{1\ \text{×}\ 4} × W_{4\ \text{×}\ j} + B_{m\ \text{×}\ j} = Y_{1\ \text{×}\ 8}
   $$
   편향 행렬 B는 출력 행렬 Y의 크기에 영향을 주지 않으므로 편향 행렬 B의 크기는 출력 행렬 Y의 크기와 같다.
   $$
   X_{1\ \text{×}\ 4} × W_{4\ \text{×}\ j} + B_{1\ \text{×}\ 8} = Y_{1\ \text{×}\ 8}
   $$
   가중치 행렬 W의 열은 출력 행렬 Y의 열과 동일해야 한다.
   $$
   X_{1\ \text{×}\ 4} × W_{4\ \text{×}\ 8} + B_{1\ \text{×}\ 8} = Y_{1\ \text{×}\ 8}
   $$
   layer 1의 가중치 행렬과 편향 행렬의 크기를 구했다.
   이제 layer 1의 출력 행렬 Y는 layer 2에서는 입력 행렬 X가 된다.

2. layer 2와 layer 3의 행렬 크기 추정하기
   이를 반복하면 layer 2와 layer 3에서의 가중치 행렬과 편향 행렬의 크기를 구할 수 있다.
   비록 은닉층과 출력층에 활성화 함수가 존재하지만 활성화 함수는 행렬의 크기에 영향을 주지 않는다.

   - layer 2: 
     $$
     X_{1\ \text{×}\ 8} × W_{8\ \text{×}\ 8} + B_{1\ \text{×}\ 8} = Y_{1\ \text{×}\ 8}
     $$

   - layer 3: 
     $$
     X_{1\ \text{×}\ 8} × W_{8\ \text{×}\ 3} + B_{1\ \text{×}\ 3} = Y_{1\ \text{×}\ 3}
     $$

   인공 신경망이 입력층에서 은닉층을 지나 출력층에서 예측값을 계산하기까지의 과정을 행렬 연산으로 가정하고 행렬의 크기를 추정해보았다.
   이와 같이 순전파를 진행하고 예측값을 구하고나서 이 다음에 인공 신경망이 해야할 일은 예측값과 실제값으로부터 오차를 계산하고, 오차로부터 가중치와 편향을 업데이트하는 일이다.
   즉, 인공 신경망의 학습 단계에 해당된다.
   이때 인공 신경망은 순전파와는 반대 방향으로 연산을 진행하며 가중치를 업데이트하는데, 이 과정을 역전파(Backpropagation)라고 한다.

---

### 3. 딥 러닝의 학습 방법

손실 함수와 옵티마이저의 개념 가지고, 딥 러닝에서 어떻게 학습을 하는지에 대해서 배워보자.

---

### 3.1 순전파(Forward Propagation)

![img](https://wikidocs.net/images/page/36033/%EC%88%9C%EC%A0%84%ED%8C%8C.PNG)

활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 딥 러닝 모델을 설계하고나면 입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향한다.
그리고 출력층에서 모든 연산을 마친 예측값이 나오게 된다.
이와 같이 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파라고 한다.

---

### 3.2 손실 함수(Loss function)

![img](https://wikidocs.net/images/page/36033/%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98.PNG)

손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수이다.
이 두 값의 차이, 즉 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아진다.
회귀에서는 평균 제곱 오차, 분류 문제에서는 크로스 엔트로피를 주로 손실 함수로 사용한다.
손실 함수의 값을 최소화하는 두 개의 매개변수의 가중치 W와 편향 b를 찾아가는 것이 DL의 학습 과정이므로 손실 함수의 선정은 매무 중요하다.

1. MSE(Mean Squared Error, MSE)
   오차 제곱 평균을 의미한다.
   연속형 변수를 예측할 때 사용된다.
   ![img](https://wikidocs.net/images/page/24987/mse.PNG)
2. 크로스 엔트로피(Cross-Entropy)
   y: 실제값 (0 or 1) / y^: 예측값 (확률)
   ![img](https://wikidocs.net/images/page/24987/%ED%81%AC%EB%A1%9C%EC%8A%A4%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC.PNG)
   낮은 확률로 예측해서 맞추거나, 높은 확률로 예측해서 틀리는 경우 loss가 더 크다.
   이진 분류(Binary Classification)의 경우 binary_crossentropy를 사용하며 다중 클래스 분류(Multi-Class Classification)일 경우 categorical_crossentropy를 사용한다.

---

### 3.3 옵티마이저(Optimizer)

![img](https://wikidocs.net/images/page/36033/%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B3%BC%EC%A0%95.PNG)

손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라진다.
여기서 배치(Batch)라는 개념에 대한 이해가 필요하다.
배치는 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양을 말한다.
전체 데이터로 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개 변수의 값을 조정할 수 있다.

1. 배치 경사 하강법(Batch Gradient Descent)
   배치 경사 하강법(Batch Gradient Descent)은 가장 기본적인 경사 하강법이다.
   배치 경사 하강법은 옵티마이저 중 하나로 오차(loss)를 구할 때 전체 데이터를 고려한다.
   ML에서는 1번의 훈련 횟수를 1 에포크라고 하는데, 배치 경사 하강법은 한 번의 에포크에 모든 매개변수 업데이트를 단 한 번 수행한다.
   배치 경사 하강법은 전체 데이터를 고려해서 학습하므로 에포크당 시간이 오래 걸리며, 메뫼를 크게 요구한다는 단점이 있으나 글로벌 미니멈을 찾을 수 있다는 장점이 있다.

   ```python
   model.fit(X_train, y_train, batch_size=len(trainX))
   ```

2. 확률적 경사 하강법(Stochastic Gradient Descent, SGD)
   기존의 배치 경사 하강법은 전체 데이터에 대해서 계산을 하다보니 시간이 너무 오래 걸린다는 단점이 있다.
   확륣적 경사 하강법은 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법이다.
   더 적은 데이터를 사용하므로 더 빠르게 계산할 수 있다.

   ![img](https://wikidocs.net/images/page/24987/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95SGD.PNG)

   매개변수의 변경폭이 불안정하고, 때로는 배치 경사 하강법보다 정확도가 낮을 수도 있지만 속도만큼은 배치 경사 하강법보다 빠르다는 장점이 있다.
   케라스에서는 아래와 같이 사용한다.

   ```python
   model.fit(X_train, y_train, batch_size=1)
   ```

3. 미니 배치 경사 하강법(Mini-Batch Gradient Descent)
   전체 데이터도 아니고, 1개의 데이토도 아니고 정해진 양에 대해서만 계산하여 매개 변수의 값을 조정하는 경사 하강법을 미니 매치 경사 하강법이라고 한다.
   미니 배치 경사 하강법은 전체 데이터를 계산하는 것보다 빠르며, SGD보다 안정적이라는 장점이 있다.
   실제로 가장 많이 사용되는 경사 하강법이다.

   ```python
   model.fit(X_train, y_train, batch_size=32) #32를 배치 크기로 하였을 경우
   ```

4. 모멘텀(Momentum)
   모멘텀은 관성이라는 물리학의 법칙을 응용한 방법이다.
   모멘텀 SGD는 경사 하강법에 관성을 더 해준다.
   모멘텀은 SGD에서 계산된 접선의 기울기에 한 시점(step) 전의 접선의 기울기값을 일정한 비율만큼 반영한다.
   이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있다.

   ![img](https://wikidocs.net/images/page/24987/%EB%A1%9C%EC%BB%AC%EB%AF%B8%EB%8B%88%EB%A9%88.PNG)

   다시 말해 로컬 미니멈에 도달했을 때, 기울기가 0이라서 기존의 경사 하강법이란면 이를 글로벌 미니멈으로 잘못 인식하여 계산이 끝났을 상황이라도 모멘텀, 즉 관성의 힘을 빌리면 값이 조절되면서 로컬 미니멈에서 탈출하는 효과를 얻을 수 있다.
   케라스에서는 다음과 같이 사용한다.

   ```python
   keras.optimizers.SGD(lr = 0.01, momentum= 0.9)
   ```

5.  아다그라드(Adagrad)
   매개변수들은 각자 의미하는 바가 다른데, 모든 매개변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적이다.
   아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킨다.
   이 때, 많은 매개변수는 학습률이 작게 설정되고 변화가 적은 매개변수는 학습률을 높게 설정한다.
   케라스에서는 다음과 같이 사용한다.

   ```python
   keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)
   ```

6. 알엠에스프로뱨(RMSprop)
   아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있는데 이를 수식으로 대체하여 이러한 단점을 개선했다.
   케라스에서는 다음과 같이 사용한다.

   ```python
   keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)
   ```

7. 아담(Adam)
   아담은 알엠에스프롭과 모멘텀 두 가지를 합친 듯한 방법으로, 방향과 학습률 두 가지를 모두 잡기 위한 방법이다.
   케라스에서는 다음과 같이 사용한다.

   ```python
   keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
   ```

---

### 3.4 역전파(Backpropagation)

인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때 어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해보자.

1. 인공 신경망의 이해(Neural Network Overview)
   우선 예제를 위해 사용될 인공 신경망에 대해서 소개한다.
   역잔파의 이해를 위해서 여기서 사용할 인공 신경망은 입력층, 은닉층, 출력층 이렇게 3개의 층을 가진다.
   또한 해당 인공 신경망은 두 개의 입력과, 두 개의 은닉층 뉴런, 두 개의 출력층 뉴런을 사용한다.
   은닉층과 출력층의 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용한다.

   ![img](https://wikidocs.net/images/page/37406/nn1_final.PNG)

   위의 그림은 여기서 사용할 인공 신경망의 모습을 보여준다.
   은닉층과 출력층의 모든 뉴런에서 변수 z가 존재하는데 여기서 변수 z는 이전 층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합을 의미한다.
   이 값은 뉴런에서 아직 시그모이드 함수를 거치지 않은 상태이다.
   즉, 활성화 함수의 입력을 의미한다.
   z 우측의 l를 지나서 존재하는 변수 h 또는 o는 z가 시그모이드 함수를 지난 후의 값으로 각 뉴런의 출력값을 의미한다.
   이번 역전파 예제에서는 인공 신경망에 존재하는 모든 가중치 W에 대해서 역전파를 업데이트하는 것을 목표로한다.
   해당 인공 신경망은 편향 b를 고려하지 않는다.

2. 순전파(Forward Propagation)

   ![img](https://wikidocs.net/images/page/37406/nn2_final_final.PNG)

   주어진 값이 위의 그림과 같을 때 순전파를 진행해보자.
   위의 그림에서 소수점 앞의 0은 생략하자.
   예를 들어 .25는 0.25를 의미한다.
   파란색 숫자는 입력값을 의미하며, 빨간색 숫자는 각 가중치를 의미한다.
   앞으로 진행하는 계산의 결과 값은 소수점 아래 여덟번째 자리까지 반올림하여 표기한다.

   각 입력은 입력층에서 은닉층 방향으로 향하면서 각 입력에 해당하는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수의 입력값이 된다.
   z1과 z2는 시그모이드 함수의 입력으로 사용되는 각각의 값에 해당된다.
   $$
   z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.3 \text{×} 0.1 + 0.25 \text{×} 0.2= 0.08
   $$

   $$
   z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.4 \text{×} 0.1 + 0.35 \text{×} 0.2= 0.11
   $$

   z1과 z2는 각각의 은닉층 뉴런에서 시그모이드 함수를 지나게 되는데 시그모이드 함수가 리턴하는 결과값은 은닉층 뉴런의 최종 출력값이다.
   식에서 각각 h1과 h2에 해당되며, 아래의 결과와 같다.
   $$
   h_{1}=sigmoid(z_{1}) = 0.51998934
   $$

   $$
   h_{2}=sigmoid(z_{2}) = 0.52747230
   $$

   h1과 h2 이 두 값은 다시 출력층의 뉴런으로 향하게 되는데 이때 다시 각각의 값에 해당되는 가중치와 곱해지고, 다시 가중합 되어 출력층 뉴런의 시그모이드 함수의 입력값이 된다.
   식에서는 각각 z3과 z4에 해당된다.
   $$
   z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.45 \text{×} h_{1} + 0.4 \text{×} h_{2} = 0.44498412
   $$

   $$
   z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.7 \text{×} h_{1} + 0.6 \text{×} h_{2} = 0.68047592
   $$

   z3와 z4이 출력층 뉴런에서 시그모이드 함수를 지난 값은 이 인공 신경망이 최종적으로 계산한 출력값이다.
   실제값을 예측하기 위한 값으로서 예측값이라고도 부른다.
   $$
   o_{1}=sigmoid(z_{3})=0.60944600
   $$

   $$
   o_{2}=sigmoid(z_{4})=0.66384491
   $$

   이제 해야할 일은 예측값과 실제값의 오차를 계산하기 위한 오차 함수를 선택하는 것이다.
   오차(Error)를 계산하기 위한 손실 함수(Loss function)로는 평균 제곱 오차 MS를 사용한다.
   식에서는 실제값을 target이라고 표현했으며, 순전파를 통해 나온 예측값을 output으로 표현하였다.
   그리고 각 오차를 모두 더하면 전체 오차 Etotal이 된다.
   $$
   E_{o1}=\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02193381
   $$

   $$
   E_{o2}=\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00203809
   $$

   $$
   E_{total}=E_{o1}+E_{o2}=0.02397190
   $$

3. 역전파 1단계(Backpropagation Step 1)
   순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트한다.
   출력층 바로 이전으이 은닉층을 N층이라고 하였을 때, 출력츨과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전 층 사이의 업데이트 하는 관계를 역전파 2단계라고 해보자.

   ![img](https://wikidocs.net/images/page/37406/nn3_final.PNG)

   역전파 1단계에서 업데이트 해야 할 가중치는 W5, W6, W7, W8 총 4개이다.
   원리 자체는 동일하므로 우선 W5에 대해서 먼저 업데이트를 진행해보자.
   경사 하강법을 수행하려면 가중치 W5를 업데이트 하기 위해서 
   $$
   \frac{∂E_{total}}{∂W_{5}}
   $$
   를 계산해야 한다.
   $$
   \frac{∂E_{total}}{∂W_{5}}
   $$
   를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있다.
   $$
   \frac{∂E_{total}}{∂W_{5}} = \frac{∂E_{total}}{∂o_{1}} \text{×} \frac{∂o_{1}}{∂z_{3}} \text{×} \frac{∂z_{3}}{∂W_{5}}
   $$
   위의 식에서 우변의 세 개의 각 항에 대해서 순서대로 계산해보자.
   우선 첫번째 항에 대해서 계산해보자.
   미분을 진행하기 전에 Etotal의 값을 상기해보자.
   Etotal은 앞서 순전파를 진행하고 계산했던 전체 오차값이다.
   식은 다음과 같다.
   $$
   E_{total}=\frac{1}{2}(target_{o1}-output_{o1})^{2} + \frac{1}{2}(target_{o2}-output_{o2})^{2}
   $$
   이에 
   $$
   \frac{∂E_{total}}{∂o_{1}}
   $$
   는 다음과 같다.
   $$
   \frac{∂E_{total}}{∂o_{1}}=2 \text{×} \frac{1}{2}(target_{o1}-output_{o1})^{2-1} \text{×} (-1) + 0
   $$

   $$
   \frac{∂E_{total}}{∂o_{1}}=-(target_{o1}-output_{o1})=-(0.4-0.60944600)=0.20944600
   $$

   이제 두번째 항을 주목해보자.
   o1이라는 값은 시그모이드 함수의 출력값이다.
   그런데 시그모이드 함수의 이분은 f(x)*(1 - f(x))이다.
   앞으로의 계산 과정에서도 계속해서 시그모이드 함수를 미분해야하는 상황이 생기므로 기억해두자.
   이에 따라서 두번째 항의 미분 결과는 다음과 같다.
   $$
   \frac{∂o_{1}}{∂z_{3}}=o_{1}\text{×}(1-o_{1})=0.60944600(1-0.60944600)=0.23802157
   $$
   마지막으로 세번째 항은 h1의 값과 동일하다.
   $$
   \frac{∂z_{3}}{∂W_{5}}=h_{1}=0.51998934
   $$
   우변의 모든 항을 계산하였다.
   이제 이 값을 모두 곱해주면 된다.
   $$
   \frac{∂E_{total}}{∂W_{5}} = 0.20944600 \text{×} 0.23802157 \text{×} 0.51998934 = 0.02592286
   $$
   이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 때가 됬다.
   하이퍼 파라미터에 해당되는 학습률(learning rate) a는 0.5라고 가정한다.
   $$
   W_{5}^{+}=W_{5}-α\frac{∂E_{total}}{∂W_{5}}=0.45- 0.5 \text{×} 0.02592286=0.43703857
   $$
   이와 같은 원리로 W6+, W7+, W8+을 계산할 수 있다.
   $$
   \frac{∂E_{total}}{∂W_{6}} = \frac{∂E_{total}}{∂o_{1}} \text{×} \frac{∂o_{1}}{∂z_{3}} \text{×} \frac{∂z_{3}}{∂W_{6}} → W_{6}^{+}=0.38685205
   $$

   $$
   \frac{∂E_{total}}{∂W_{7}} = \frac{∂E_{total}}{∂o_{2}} \text{×} \frac{∂o_{2}}{∂z_{4}} \text{×} \frac{∂z_{4}}{∂W_{7}} → W_{7}^{+}=0.69629578
   $$

   $$
   \frac{∂E_{total}}{∂W_{8}} = \frac{∂E_{total}}{∂o_{2}} \text{×} \frac{∂o_{2}}{∂z_{4}} \text{×} \frac{∂z_{4}}{∂W_{8}} → W_{8}^{+}=0.59624247
   $$

4. 역전파 2단계(Backpropagation Step 2)

   ![img](https://wikidocs.net/images/page/37406/nn4.PNG)

   1단계를 완료하였다면 이제 입력츨 방향으로 이동하며 다시 계산을 이어간다.
   위의 그림에서 빨간색 화살표는 순전파의 정반대 방향인 역전파의 방향으로 보여준다.
   현재 인공 신경망은 더 많은 경우라면 입력층 방향으로 한 단계식 계속해서 계산해가야 한다.

   이번 단계에서 계산할 가중치는 W1, W2, W3, W4이다.
   원리 자체는 동일하므로 우선 W1에 대해서 먼저 업데이트를 진행해보자.
   경사 하강법을 수행하려면 가중치 W1를 업데이트 하기 위해서 
   $$
   \frac{∂E_{total}}{∂W_{1}}
   $$
   를 계산해야 한다.
   $$
   \frac{∂E_{total}}{∂W_{1}}
   $$
   를 계산하기 위해 미분의 연쇄 법칙(Chain rule)에 따라서 이와 같이 풀어 쓸 수 있다.
   $$
   \frac{∂E_{total}}{∂W_{1}} = \frac{∂E_{total}}{∂h_{1}} \text{×} \frac{∂h_{1}}{∂z_{1}} \text{×} \frac{∂z_{1}}{∂W_{1}}
   $$
   위의 식에서 우변의 첫번째 항인 
   $$
   \frac{∂E_{total}}{∂h_{1}}
   $$
   는 다음과 같이 다시 식을 풀어서 쓸 수 있다.
   $$
   \frac{∂E_{total}}{∂h_{1}} = \frac{∂E_{o1}}{∂h_{1}} + \frac{∂E_{o2}}{∂h_{1}}
   $$
   위의 식의 우변의 두 항을 각각 구해보자.

   우선 첫번째 항 
   $$
   \frac{∂E_{o1}}{∂h_{1}}
   $$
   에 대해서 항을 분해 및 계산해보자.
   $$
   \frac{∂E_{o1}}{∂h_{1}} = \frac{∂E_{o1}}{∂z_{3}} \text{×} \frac{{∂z_{3}}}{∂h_{1}} = \frac{∂E_{o1}}{∂o_{1}} \text{×} \frac{∂o_{1}}{∂z_{3}} \text{×} \frac{{∂z_{3}}}{∂h_{1}}
   $$

   $$
   = -(target_{o1}-output_{o1}) \text{×} o_{1}\text{×}(1-o_{1}) \text{×} W_{5}
   $$

   $$
   = 0.20944600 \text{×} 0.23802157 \text{×} 0.45 = 0.02243370
   $$

   이와 같은 원리로 
   $$
   \frac{∂E_{o2}}{∂h_{1}}
   $$
   또한 구한다.
   $$
   \frac{∂E_{o2}}{∂h_{1}} = \frac{∂E_{o2}}{∂z_{4}} \text{×} \frac{{∂z_{4}}}{∂h_{1}} = \frac{∂E_{o2}}{∂o_{2}} \text{×} \frac{∂o_{2}}{∂z_{4}} \text{×} \frac{{∂z_{4}}}{∂h_{1}} = 0.00997311
   $$

   $$
   \frac{∂E_{total}}{∂h_{1}} = 0.02243370 + 0.00997311 = 0.03240681
   $$

   이제 
   $$
   \frac{∂E_{total}}{∂W_{1}}
   $$
   를 구하기 위해서 필요한 첫번째 항을 구했다.
   나머지 두 항에 대해서 구해보자.
   $$
   \frac{∂h_{1}}{∂z_{1}} = h_{1}\text{×}(1-h_{1}) = 0.51998934(1-0.51998934)=0.24960043
   $$

   $$
   \frac{∂z_{1}}{∂W_{1}} = x_{1} = 0.1
   $$

   즉, 
   $$
   \frac{∂E_{total}}{∂W_{1}}
   $$
   은 다음과 같다.
   $$
   \frac{∂E_{total}}{∂W_{1}} = 0.03240681 \text{×} 0.24960043 \text{×} 0.1 = 0.00080888
   $$
   이제 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트 할 수 있다.
   $$
   W_{1}^{+}=W_{1}-α\frac{∂E_{total}}{∂W_{1}}=0.1- 0.5 \text{×} 0.00080888=0.29959556
   $$
   이와 같은 원리로 W2+, W3+, W4+을 계산할 수 있다.
   $$
   \frac{∂E_{total}}{∂W_{2}} = \frac{∂E_{total}}{∂h_{1}} \text{×} \frac{∂h_{1}}{∂z_{1}} \text{×} \frac{∂z_{1}}{∂W_{2}}  → W_{2}^{+}=0.24919112
   $$

   $$
   \frac{∂E_{total}}{∂W_{3}} = \frac{∂E_{total}}{∂h_{2}} \text{×} \frac{∂h_{2}}{∂z_{2}} \text{×} \frac{∂z_{2}}{∂W_{3}}  → W_{3}^{+}=0.39964496
   $$

   $$
   \frac{∂E_{total}}{∂W_{4}} = \frac{∂E_{total}}{∂h_{2}} \text{×} \frac{∂h_{2}}{∂z_{2}} \text{×} \frac{∂z_{2}}{∂W_{4}} → W_{4}^{+}=0.34928991
   $$

5. 결과 확인

   ![img](https://wikidocs.net/images/page/37406/nn1_final.PNG)

   업데이트 된 가중치에 대해서 다시 한 번 순전파를 진행하여 오차가 감소하였는지 확인해보자.
   $$
   z_{1}=W_{1}x_{1} + W_{2}x_{2}=0.29959556 \text{×} 0.1 + 0.24919112 \text{×} 0.2= 0.07979778
   $$

   $$
   z_{2}=W_{3}x_{1} + W_{4}x_{2}=0.39964496 \text{×} 0.1 + 0.34928991 \text{×} 0.2= 0.10982248
   $$

   $$
   h_{1}=sigmoid(z_{1}) = 0.51993887
   $$

   $$
   h_{2}=sigmoid(z_{2}) = 0.52742806
   $$

   $$
   z_{3}=W_{5}h_{1}+W_{6}h_{2} = 0.43703857 \text{×} h_{1} + 0.38685205 \text{×} h_{2} = 0.43126996
   $$

   $$
   z_{4}=W_{7}h_{1}+W_{8}h_{2} = 0.69629578 \text{×} h_{1} + 0.59624247 \text{×} h_{2} = 0.67650625
   $$

   $$
   o_{1}=sigmoid(z_{3})=0.60617688
   $$

   $$
   o_{2}=sigmoid(z_{4})=0.66295848
   $$

   $$
   E_{o1}=\frac{1}{2}(target_{o1}-output_{o1})^{2}=0.02125445
   $$

   $$
   E_{o2}=\frac{1}{2}(target_{o2}-output_{o2})^{2}=0.00198189
   $$

   $$
   E_{total}=E_{o1}+E_{o2}=0.02323634
   $$

   기존의 전체 오차 Etotal가 0.02397190였으므로 1번의 역전파로 오차가 감소한 것을 확인할 수 있다.
   인공 신경망의 학습은 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것 말한다.

---

### 3.5 에포크와 배치 크기와 이터레이션(Epochs and Batch size and Iteration)

기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트한다.
ML에서는 이 과정을 학습이라고 한다.
이를 현실의 학습에 비유하면 사람은 문제지의 문제를 풀고, 정답지의 정답을 보면서 채점을 하면서 부족했던 점을 깨달으며 머릿속의 지식이 업데이트되는 과정이다.

그런데 사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별이다.
어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점하는데 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부한다.
문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습한다든 것이다.
또한 게으른 사람은 문제지를 3번 공부하는데, 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부한다.

기계도 똑같다.
같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있다.

![img](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)

위의 그림은 에포크와 배치 크기와 이터레이션의 차이를 보여준다.
위의 그림의 예제를 통해 설명해보자.

1. 에포크(Epoch)
   에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태를 말한다.
   전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태를 말한다.

   만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습한다.
   문제지에 비유하면 문제지를 50번 푼 셈이다.
   이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있다.

2. 배치 크기(Batch size)
   배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말한다.
   현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제이다.
   사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다고 했다.
   기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트한다.
   여기서 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 거다.

   사람이 2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이때 배치 크기는 200이다.
   기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 한다.

   여기서 주의할 점은 배치 크기와 배치의 수는 다른 개념이라는 점이다.
   전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10이다.
   이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 하다.
   이때 배치의 수를 이터레이션이라고 한다.

3. 이터레이션(Iteration)
   이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수를 말한다.
   또는 한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수이기도 한다.
   전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10개이다.
   이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미이다.
   SGD를 이 개념을 가지고 다시 설명하면, SGD는 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행한다.

