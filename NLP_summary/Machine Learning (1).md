# Machine Learning (1)

Source: https://wikidocs.net/21669, https://wikidocs.net/21679, https://wikidocs.net/32012, https://wikidocs.net/21670, https://wikidocs.net/22881, https://wikidocs.net/35821, https://wikidocs.net/37001, https://wikidocs.net/35476

---

### 0. ML의 개요

AI가 최근 몇 년간 4차 산업혁명의 주 키워드로 언급되고 있다.
AI는 여러 가지 의미를 포괄하고 있지만, 지금에 이르러 사람들이 말하는 AI는 바로 머신 러닝(Machine Learning)과 ML의 한 갈래인 딥 러닝(Deep Learning)을 의미한다.
혹자는 규칙을 찾아 프로그래밍을 하는 전통적인 프로그래밍 방법에서, 스스로 규칙을 찾아내기는 ML이 새로운 프로그래밍의 패러다임이 될 것이라고 말하기도 한다.
그만큼 ML은 기존에 해결할 수 없었던 수 많은 문제들에 대한 최적의 해결방법을 제시해주고 있다.

ML은 이미지 인식, 영상 처리, 알파고와 같은 분야 뿐만 아니라 NLP에 있어서도 유용하게 쓰인다.
특히 ML의 한 갈래인 딥러닝은 기존의 통계 기반에서 접근했던 NLP의 성능을 훨씬 뛰어 넘는 성능을 보이고 있어, 현재에 이르러서는 NLP에 있어 딥 러닝은 필수가 되었다.

----

### 1. 머신 러닝이란

딥러닝을 포함하고 있는 개념인 머신러닝에 대한 개념에 대해서 학습하자.

---

### 1.1 ML이 아닌 접근 방법의 한계

ML을 이해하기 위해 머신러닝이 아닌, 기존의 프로그래밍 접근 방법을 통해 프로그램을 작성했을 때 한계가 있는 경우를 예로 들어보자.

Ex) 주어진 사진으로부터 고양이 사진인지 강아지 사진인지 판별하는 일.
위 문제는 실제로 2017년에 있었던 DGIST의 딥러닝 경진대회의 문제임 밝힌다.

사람에게 있어 위와 같은 일은 어렵지 않다.
직관적으로 고양이 사진인지, 강아지 사진인지 아주 쉽게 알 수 있다.
그런데 프로그램 즉, 기계에서 이러한 일은 쉽지 않다.
그 이유를 알아봅시다.

해당 프로그램을 이미지라는 것을 입력으로 받아서, 이미지가 강아지에 속하는지 고양이에 속하는지의 결과값을 리턴하는 프로그램이 될 것이다.

```python
def prediction(이미지 as input):
    어떻게 코딩해야하지?
    return 결과
```

그런데 사실 구글에서 강아지와 고양이 사진을 검색해보면 알겠지만, 사진이란 건 사진을 보는 각도, 조명, 타켓의 변형(자세의 변화)에 따라서 너무나 천차만별이라 사진으로부터 공통된 명확한 특징을 잡아내는 것이 쉽지 않는다.

결론을 미리 언급하자면 해당 프로그램은 숫자를 정렬하는 것과 같은 명확한 알고리즘이 애초에 존재하지 않는다.

![img](https://wikidocs.net/images/page/21679/%EA%B3%A0%EC%96%91%EC%9D%B4_%EC%95%A1%EC%B2%B42.jpg)

![img](https://wikidocs.net/images/page/21679/%EA%B3%A0%EC%96%91%EC%9D%B4_%EC%97%89%EB%8D%A9%EC%9D%B4.jpg)

역사적으로 이러한 이미지 인식 분야에서 특징을 잡아내기 위한 시도들이 있었다.
이미지의 shape나 edge와 같은 것들을 찾아내서 알고리즘화 하려고 시도하고, 다른 사진 이미지가 들어오면 전반적인 상태를 비교하여 분류하려고 한 것이다.

하지만 그러한 시도들은 위에선 언급한 이유로 결국 특징을 잡아내는 것에 한계가 있을 수 밖에 없다.
위와 같은 예제를 언급한 이유는 ML은 이에 대한 해결책이 될 수 있기 때문이다.

---

### 1.2 ML은 기존 프로그래밍의 한계에 대한 해결책이 될 수 있다

![img](https://wikidocs.net/images/page/21679/%EC%A0%84%ED%86%B5_vs_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.png)

ML이 위의 문제를 해결할 수 있는 이유는 해결을 위한 접근 방법이 앞서 언급한 기존의 프로그래밍과는 다르기 때문이다.
위의 이미지에서 위쪽은 기존의 프로그래밍 방법으로 접근한 것이고, 아래쪽은 ML의 접근 방법을 보여준다.

ML은 주어진 데이터로부터 결과를 찾는 것에 초점을 맞추는 것이 아니라, 주어진 데이터로부터 규칙성을 찾는 것에 초점이 맞추어져 있다.
주어진 데이터로부터 규칙성을 찾는 과정을 우리는 학습(training)이라고 한다.

일단 규칙성을 발견해내면, 그 후에 들어오는 새로운 데이터에 대해서 발견한 규칙성을 기준으로 정답을 찾아내는데, 이는 기존의 프로그래밍 방식으로 접근하기 어려웠던 문제의 해결책이 되기도 한다. 

---

### 2. ML 훑어보기

ML의 특징에 대해서 배워보자.
DL 또한 ML에 속하므로, 아래의 ML의 특징들은 모두 DL의 특징이기도 한다.

---

### 2.1 ML모델의 평가

![img](https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)

실제 모델을 평가하기 위해서 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리하는 것이 일반적이다.
다만, 이 책의 목적은 개념 학습이므로 일부 실습에서는 별도로 세 가지로 분리하지 않고 훈련용, 테스트용으로 분리해서 사용한다.
그렇다면 훈련용, 테스트용 두 가지로만 나눠서 테스트 데이터로 한 번만 테스트하면 더 편할텐데 왜 검즘용 데이터를 만들어 놓는 것일까.

검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도이다.
더 정확히는 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도이다.
하이퍼파라미터(초매개변수)란 값에 따라서 모델의 성능에 영향을 주는 매개변수들을 말한다.

이 두 값 하이퍼파라미터와 매개변수의 가장 큰 차이는 하이퍼파라미터는 보통 사용자가 직접 정해줄 수 있는 변수라는 점이다.
선형 회귀에서 배우게 되는 경사 하경법애서 학습률(learning rate)이 이에 해당되며, DL에서는 은닉층의 수, 뉴런의 수, 드롭아웃 비율등이 이에 해당된다.
반면 여기서 언급하는 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값이다.
정리하면 절대적인 정의라고는 할 수 없지만, 하이퍼파라미터는 사람이 정하는 변수인 반면, 매개변수는 기계가 훈련을 통해서 바꾸는 변수라고 할 수 있으며 이와 같은 기준으로 변수의 이름을 명명한다.

훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝(tuning)한다.
또한 이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 점점 맞추어져 가기 시작한다.

하이퍼파라미터 튜닝이 끝났다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않다.
이제 모델은 검증용 데이터에 대해서도 일정 부분 최적화가 되어있기 때문이다.
모델에 대한 평가는 모델이 아직까지 보지 못한 데이터로 하는 것이 가장 바람직하다.
검증이 끝났다면 테스트 데이터를 가지고 모델의 진짜 성능을 평가한다.
비유하자면 훈련 데이터는 문제지, 검증 데이터는 모의고사, 테스트 데이터는 실력을 최종적으로 평가하는 수능 시험이라고 할 수 있다.

만약, 검증 데이터와 테스트 데이터를 나눌 만큼 데이터가 충분하지 않다면 k-폴드 교차 검증이라는 또 다른 방법을 사용하기도 한다.

---

### 2.2 분류(Classification)와 회귀(Regression)

전부라고는 할 수 없지만, ML의 많은 문제는 분류 또는 회귀 문제에 속한다.

분류는 또한 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification)로 나눈다.
엄밀히는 다중 레이블 분류(Multi-label Classification)라는 또 다른 문제가 존재한다.

1. 이진 분류 문제(Binary Classification)
   이진 분류는 주어진 입력에 대해서는 둘 중 하나의 답을 정하는 문제이다.
   시험 성적에 대해서 합격, 불합격인지 판단하고 메일로부터 정상 메일, 스팸 메일인지를 판단하는 문제등이 이에 속한다.
2. 다중 클래스 분류(Multi-Class Classification)
   다중 클래스는 분류는 주어진 입력에 대해서 두 개 이상의 정해진 선택지 중에서 답을 정하는 문제이다.
   예를 들어 서점 아르바이트를 하는데 과학, 영어 IT, 학습지, 만화라는 레이블이 각각 붙여져 있는 5개의 책장이 있다고 하자.
   새 책이 입고되면, 이 책은 다섯 개의 책장 중에서 분야에 맞는 적절한 책장에 책을 넣어야 한다.
   이 때의 다섯 개의 선택지를 주로 카테고리 또는 범주 또는 클래스라고 하며, 주어진 입력으로부터 정해진 클래스 중 하나로 판단하는 것을 다중 클래스 분류 문제라고 한다.
3. 회귀 문제(Regression)
   회귀 문제는 분류 문제처럼 0 또는 1이나 과학 책장, IT 책장 등과 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가진다.
   예를 들어 시험 성적을 예측했는데 5시간 공부하였을 때 80점, 5시간 1분 공부했을 때는 80.5점, 7시간 공부하였을 때는 90점이 나오는 것과 같은 문제가 있다.
   그 외에도 시계열 데이터를 이용한 주가 예측, 생산량 예측, 지수 예측 들이 이에 속한다.

---

### 2.3 지도학습(Supervised Learning)과 비지도 학습(Unsupervised Learning)

ML은 크게 지도 학습, 비지도 학습, 강화 학습으로 나눈다.

1. 지도 학습
   지도 학습이란 레이블(Label)이라는 정답과 함계 학습하는 것을 말한다.
   이는 앞서 데이터의 분리에서 상세히 설명한 바 있다.
   레이블이라는 말 외에도 y, 실제값 등으로 부르기도 한다.

   이때 기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습을 하게 되는데 예측값은 y^과 같이 표현하기도 한다.

2. 비지도 학습
   반면, 비지도 학습은 레이블이 없이 학습하는 것을 말한다.
   예를 들어 토픽 모델링의 LDA는 비지도 학습에 속하며, Word2Vec은 마치 지도 학습을 닮았지만, 비지도 학습에 속한다.

---

### 2.4 샘플(Sample)과 특성(Feature)

많은 ML 문제가 1개 이상의 독립 변수 x를 가지고 종속 변수 y를 예측하는 문제이다.
많은 ML 모델들, 특히 인공 신경망 모델은 독립 변수, 종속 변수, 가중치, 편향들을 행렬 연산을 통해 연산하는 경우가 많다.
그래서 아픙로 인공 신경망을 배우게 되면 훈련 데이터를 행렬로 표현하는 경우를 많이 보게 될 것이다.
독립 변수 x의 행렬을 X라고 했을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X는 다음과 같다.

![img](https://wikidocs.net/images/page/35821/n_x_m.PNG)

이때 머신 러닝에서는 하나의 데이터, 하나의 행을 샘플(Sample)이라고 부른다. (데이터베이스에서는 레코드라고 부르는 단위이다.)
종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성(feature)이라고 부른다.

---

### 2.5 혼동 행렬(Confusion Matrix)

ML에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)이라고 한다.
하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않는다.
이를 위해서 사용하는 것이 혼동행렬(Confusion Matrix)이다.

예를 들어 양성(Positive)과 음성(Negative)을 구분하는 이진 분류가 있다고 하였을 때, 혼동 행렬은 다음과 같다.
각 열은 예측값을 나타내며, 각 행은 실제값을 나타낸다.

|  -   |  참  | 거짓 |
| :--: | :--: | :--: |
|  참  |  TP  |  FN  |
| 거짓 |  FP  |  TN  |

이를 각각 TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative)라고 하는데 True는 정답을 맞춘 경우고 False는 정답을 맞추지 못한 경우이다.
그리고 Positive와 Negative는 각각 제시했던 정답이다.
즉, TP는 양성(Positive)이라고 대답하였고 실제로 양성이라서 정답을 맞춘 경우이다.
TN은 음성(Negative)이라고 대답하였는데 실제로 음성이라서 정답을 맞춘 경우이다.

그럼 FP는 양성이라고 대답했는데, 음성이라서 정답을 틀린 경우이며 FN은 음성이라고 대답하였는데 양성이라서 정답을 틀린 경우가 된다.
그리고 이 개념을 사용하면 또 새로운 개념인 정밀도(Precision)과 재현률(Recall)이 된다.

1. 정밀도(Precision)
   정밀도는 양성이라고 대답한 전체 케이스에 대한 TP의 비율이다.
   즉, 정밀도를 수식으로 표현하면 다음과 같다.
   $$
   정밀도 = \frac{TP}{TP + FP}
   $$

2. 재현률(Recall)
   재현률은 실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율이다.
   즉 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지를 나타낸다.
   $$
   재현률 = \frac{TP}{TP + FN}
   $$

---

### 2.6 과적합(Overfitting)과 과소 적합(Underfitting)

학생의 입장이 되어 같은 문제지를 과하게 많이 풀어서 문제 번호만 봐도 정답을 맞출 수 있게 되었다고 가정하자.
그런데 다른 문제지나 시험을 보면 점수가 안 좋다면 그게 의미가 있을까.

ML에서 과적합(Overfitting)이란 훈련 데이터를 과하게 학습한 경우를 말한다.
훈련 데이터는 실제로 존재하는 많은 데이터의 일부에 불과하다.
그런데 기계가 훈련 데이터에 대해서만 과하게 학습하면 테스트 데이터나 실제 서비스에서의 데이터에 대해서는 정확도가 좋지 않은 현상이 발생한다.

예를 들어 강아지 사진과 고양이 사진을 구분하는 기계가 있을 때, 검은색 강아지 사진 훈련 데이터를 과하게 학습하면 기계는 나중에 가서 흰색 강아지나, 갈색 강아지를 보고도 강아지가 아니라고 판단하게 된다. 이는 훈련 데이터에 대해서 지나친 일반화를 한 상황이다.

과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황이 발생한다.
아래의 그래프는 과적합 상황에서 발생할 수 있는 훈련 횟수에 따른 데이터의 오차와 테스트 데이터의 오차의 변화를 보여준다.

![img](https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png)

위 그래프는 스팸 메일 분류하기 실습에서 훈련 데이터에 대한 훈련 횟구를 30회로 주어서 의도적으로 과적합을 발생시켰을 때의 그래프이다.
X축의 에포크(epoch)는 전체 훈련 데이터에 대한 횟수를 의미한다.

스팸 메일 분류하기 실습은 에포크가 3~4를 넘어가게 되면 과적합이 발생한다.
위의 그래프는 테스트 데이터에 대한 오차가 점차 증가하는 양상을 보여준다.
반대로 말하면 훈련 데이터에 대한 정확도는 높지만, 테스트 데이터는 정확도가 낮은 상황이라고 말할 수도 있다.
즉, 테스트 데이터의 오차가 증가하기 전이나, 정확도가 감소하기 전에 훈련을 멈추는 것이 바람직하다.

과적합 방지를 위해 테스트 데이터의 성능이 낮아지기 전에 훈련을 멈추는 것이 바람직하다고 했는데, 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 반대로 과소적합(Underfitting)이라고 한다.
과소 적합은 훈련 자체가 부족한 상태이므로 과대 적합과는 달리 훈련 데이터에 대해서도 보통 정확도가 낮다는 특징이 있다.

이러한 두 가지 현상을 과적합과 과소 적합이라고 부르는 이유는 ML에서 학습 또는 훈련이라고 하는 과정을 적합(fitting)이라고도 부를 수 있기 때문이다.
모델이 주어진 데이터에 대해서 적합해져가는 과정이기 때문이다.

DL을 할 때는 과적합을 막을 수 있는 드롭 아웃(Drop out), 조기 종료(Early Stopping)과 같은 몇 가지 방법이 존재한다.

---

### 3. 선형 회귀(Linear Regression)

DL을 이해하기 위해서는 선형 회귀(Linear Regression)와 로지스틱 회귀(Logistic Regression)를 이해할 필요가 있다.
이번에는 ML에서 쓰이는 용어인 가설(Hypothesis), 손실 함수(Loss Function) 그리고 경사 하강법(Gradient Descent)에 대한 개념과 선형 회귀에 대해서 이해해보자.

---

### 3.1 선형 회귀

시험 공부라는 시간을 늘리면 늘릴 수록 성적이 잘 나온다.
하루에 걷는 횟수를 늘릴 수록, 몸무게는 줄어든다.
집의 평수가 클 수록, 집의 매매 가격은 비싼 경향이 있다.
이는 수학적으로 생각해보면 어떤 요인의 수치에 따라서 특정 요인의 수치가 영향을 받고있다고 말할 수 있다.
조금 더 수학적인 표현을 써보면 어떤 변수의 값에 따라서 특정 변수의 값이 영향을 받고 있다고 볼 수 있다.
다른 변수의 값을 변하게하는 변수를 x, 변수 x에 의해서 값이 종속적으로 변하는 변수 y라고 해보자.

이때 변수 x의 값은 독립적으로 변할 수 있는 겅에 반해, y값은 계속해서 x의 값에 의해서, 종속적으로 결정되므로 x를 독립 변수, y를 종속 변수라고도 한다.
선형 회귀는 한 개 이상의 독립 변수 x와 y의 선형 관계를 모델링한다.
만약, 독립 변수 x가 1개라면 단순 선형 회귀라고 한다.

1. 단순 선형 회귀 분석(Simple Linear Regression Analysis)
   $$
   y = {Wx + b}
   $$
   위의 수식은 단순 선형 회귀의 수식을 보여준다.
   여기서 독립 변수 x와 곱해지는 값 W를 ML에서는 가중치(weight), 별도로 더해지는 값 b를 편향(bias)이라고 한다.
   직선의 방정식에서는 각각 직선의 기울기와 절편을 의미한다.
   W와 b가 없이 y와 x란 수식은 y는 x와 같다는 하나의 식 밖에 표현하지 못한다.
   그래프 상으로 말하면, 하나의 직선밖에 표현하지 못한다.
   $$
   y = {x}
   $$
   다시 말해 W와 b의 값을 적절히 찾아내면 x와 y의 관계를 적절히 모델링한 것이 된다.

2. 다중 선형 회귀 분석(Multiple Linear Regression Analysis)
   $$
   y = {W_1x_1 + W_2x_2 + ... W_nx_n + b}
   $$
   잘 생각해보면 집의 매매 가격은 단순히 평수가 크다고 결정되는 것이 아니라 집의 층의 수, 방의 개수, 지하철 역과의 거리와도 영향이 있는 듯 하다.
   이제 이러한 다수의 요소를 가지고 집의 매매 가격을 예측해보고 싶어진다.
   y는 여전히 1개이지만 이제 x는 1개가 아니라 여러 개가 되었다.
   이제 이를 다중 선형 회귀 분석이라고 한다.
   이에 대한 실습은 후에 진행하자.

---

### 3.2 가설(Hypothesis) 세우기

단순 선형 회귀를 가지고 문제를 풀어보자.
어떤 학생의 공부 시간에 따라서 다음과 같은 점수를 얻었다는 데이터가 있다.

| hours(x) | score(y) |
| :------: | :------: |
|    2     |    25    |
|    3     |    50    |
|    4     |    42    |
|    5     |    61    |

이를 좌표 평면애 그려보면 다음과 같다.

![img](https://wikidocs.net/images/page/53560/%EA%B7%B8%EB%A6%BC1.PNG)

알고있는 데이터로부터 x와 y의 관계를 유추해보고, 이 학생이 6시간, 7시간, 8시간을 공부하였을 때의 성적을 예측해ㅂㅎ자.
x와 y의 관계를 유추하기 위해서 수학적으로 식을 세워보게 되는데 ML에서는 이러한 식을 가설이라고 한다.
아래의 H(x)에서 H는 Hypothesis를 의미한다.
사실 선형 회귀의 가설은 이미 아래와 같이 널리 알려져 있다.
$$
H(x) = {Wx + b}
$$
![img](https://wikidocs.net/images/page/21670/W%EC%99%80_b%EA%B0%80_%EB%8B%A4%EB%A6%84.PNG)

위의 그림은 W와 b의 값에 따라서 천차만별로 그려지는 직선의 모습을 보여준다.
중학교 수학 과정인 직선의 방정식을 알고있다면, 위의 가설에서 W는 직선의 기울기이고 b는 절편으로 직선을 표현함을 알 수 있다.
결국 선형 회귀는 주어진 데이터로부터 y와 x의 관계를 가장 잘 나타내는 직선을 그리는 일이다.
그리고 어떤 직선인지 결정하는 것은 W와 b의 값이므로 선형 회귀에서 해야할 일은 결국 적절한 W와 b를 찾아내는 일이 된다.

아직은 방법을 모르지만, 어떤 방법을 사용하여 적절한 W와 b의 값을 찾은 덕택에 y와 x의 관계를 가장 잘 나타내는 직선을 좌표 평면 상에서 그렸다고 한 번 가정해보자.
이 적선을 x가 6일 때, 7일 때, 8일 때에 대해서도 계속해서 직선을 그저 이어그린다면 이 학생이 6시간 공부했을 때의 예상 점수를 말할 수 있게 된다.

---

### 3.3 비용 함수(Cost function): 평균 제곱 오차(MSE)

앞서 주어진 데이터에서 x와 y의 관계를 W와 b를 이용하여 식을 세우는 일을 가설이라고 언급했다.
그리고 이제 해야할 일은 문제에 대한 규칙을 가장 잘 표현하는 W와 b를 찾는 일이다.
그리고 이제 해야 할 일은 문제에 대한 규칙을 가장 잘 표현하는 W와 b를 찾는 일이다.
ML은 W와 b를 찾기 위해서 실제값과 가설로부터 얻은 예측값의 오차를 계싼하는 식을 세우고, 이 식의 값을 최소화하는 최적의 W와 b를 찾아냅니다.

이 때 실제값과 예측값에 대한 오차에 대한 식을 목적 함수(Objective function) 또는 비용 함수(Cost function) 또는 손실 함수(Loss function)라고 한다.
함수의 값을 최소화하거나, 최대화하거나 하는 목적을 가진 함수를 목적 함수라고 한다.
그리고 값을 최소화하려고 하면 이를 비용 함수 또는 손실 함수라고 한다.

비용 함수는 단순히 실제값과 예측값에 대한 오차를 표현하면 되는 것이 아니라, 예측값의 오차를 줄이는 일에 최적화 된 식이어야 한다.
DL에는 다양한 문제들이 있고, 각 문제들에는 적합한 비용 함수들이 있다.
회귀 문제의 경우에는 주로 평균 제곱 오차(Mean Squared Error, MSE)가 사용된다.

![img](https://wikidocs.net/images/page/53560/%EA%B7%B8%EB%A6%BC3.PNG)

위의 그래프에 임의의 W의 값 13과 임의의 b의 값 1을 가진 직선을 그렸다.
임의로 그린 직선으로 정답이 아니다.
이제 이 직선으로부터 서서리 W와 b의 값을 바꾸면서 정답인 직선을 찾아내야 한다.

사실 y와 x의 관계를 가장 잘 나타내는 직선을 그린다는 것은 위의 그림에서 모든 점들과 위치적으로 가장 가까운 직선을 그린다는 것과 같다.
이제 오차(error)를 정의하자.
오차는 주어진 데이터에서 각 x에서의 실제값 y와 위의 직선에서 예측하고 있는 H(x)값의 차이를 말한다.
즉, 위의 그림에서 ↕는 각 점에서의 오차의 크기를 보여준다.
오차를 줄여가면서 W와 b의 값을 찾아내기 위해서는 전체 오차릐 크기를 구해야 한다.

오차의 크기를 측정하기 위한 가장 기본적인 방법은 각 오차를 모두 더하는 방법이 있다.
위의 y=13x+1 직선이 예측한 예측값을 각각 실제값으로부터 오차를 계산하여 표를 만들어보면 아래와 같다.

| hours(x) |  2   |  3   |  4   |  5   |
| :------: | :--: | :--: | :--: | :--: |
|  실제값  |  25  |  50  |  42  |  61  |
|  예측값  |  27  |  40  |  53  |  66  |
|   오차   |  -2  |  10  |  -7  |  -5  |

그런데 수식적으로 단순히 '오차 = 실제값 - 예측값' 이라고 정의한 후에 모든 오차를 더하면 음수 오차도 있고, 양수 오차도 있으므로 오차의 절대적인 크기를 구할 수가 없다.
그래서 모든 오차를 제곱하여 더하는 방법을 사용한다.
다시 말해 위의 그림에서의 모든 점과 직선 사이의 ↕ 거리를 제곱하고 모두 더한다.
이를 수식으로 표현하면 아래와 같다.
단, 여기서 n은 갖고 있는 데이터의 개수를 의미한다.
$$
\sum_{i=1}^{n} \left[y^{(i)} - H(x^{(i)})\right]^2 = (-2)^{2} + 10^{2} + (-7)^{2} + (-5)^{2} = 178
$$
이때 데이터의 개수인 n으로 나누면, 오차의 제곱합에 대한 평균을 구할 수 있는데 이를 평균 제곱 오차(MSE)라고 한다.
수식은 아래와 같다.
$$
\frac{1}{n} \sum_{i=1}^{n} \left[y^{(i)} - H(x^{(i)})\right]^2 = 178 / 4 = 44.5
$$
y=13x+1의 예측값과 실제값의 평균 제곱 오차의 값은 44.5이다.
균 제곱 오차의 값을 최소값으로 만드는 WW와 bb를 찾아내는 것이 정답인 직선을 찾아내는 일이다.
평균 제곱 오차를 WW와 bb에 의한 비용 함수(Cost function)로 재정의해보면 다음과 같다.
$$
cost(W, b) = \frac{1}{n} \sum_{i=1}^{n} \left[y^{(i)} - H(x^{(i)})\right]^2
$$
모든 점들과의 오차가 클 수록 평균 제곱 오차는 커지며, 오차가 작아질 수록 평균 제곱 오차는 작아진다.
그러므로 이 평균 최곱 오차. 즉, Cost(W,b)를 최소가 되게 만드는 W와 b를 구하면 결과적으로 y와 x의 관계를 가장 잘 나타내는 직선을 그릴 수 있다.
$$
W, b → minimize\ cost(W, b)
$$

---

### 3.4 옵티마이저(Optimizer): 경사하강법(Gradient Descent)

선형 회귀를 포함함 수 많은 ML, DL의 학습은 결국 비용 함수를 최소화하는 매개 변수인 W와 b을 찾기 위한 작업을 수행한다.
이때 사용되는 알고리즘을 옵티마이저 또는 최적화 알고리즘이라고 부른다.

그리고 이 옵티마이저를 통해 적절한 W와 b를 찾아내는 과정을 ML에서는 학습(training)이라고 부른다.
여기서는 가장 기본적인 옵티마이저 알고리즘인 경사 하강법(Gradient Descent)에 대해서 배운다.

경사 하강법을 이해하기 위해서 cost와 기울기 W와의 관계를 이해해야 한다.
W는 ML 용어로는 가중치라고 불리지만, 직선의 방정식 관점에서 보면 직선의 기울기를 의미하고 있다.
아래의 기울기 W가 지나치게 높거나, 낮을 때 어떻게 오차가 커지는지 보여준다.

![img](https://wikidocs.net/images/page/53560/%EA%B7%B8%EB%A6%BC4.PNG)

위의 그림에서 주황색선은 기울기 W가 20일 때, 초록색선은 기울기 W가 1일 때를 보여준다.
각각 y=20x, y=x에 해당되는 직선되는 직선이다.
↕는 각 점에서의 실제값과 두 직선의 예측값과의 오차를 보여준다.
이는 앞서 예측에 사용했던 y=13x+1 직선보다 확연히 큰 오차값들이다.
즉, 기울기가 지나치게 크면 실제값과 예측값의 오차가 커지고, 기울기가 지나치게 작아도 실제값과 예측값의 오차가 커진다.
사실 bb 또한 마찬가지인데 bb가 지나치게 크거나 작으면 오차가 커진다.

설명의 편의를 위해 편향 bb가 없이 단순히 가중치 WW만을 사용한 y=Wx라는 가설 H(x)를 가지고, 경사 하강법을 수행한다고 해보자.
비용 함수의 값 cost(W)는 cost라고 줄여서 표현하자.
이에 따라 W와 cost의 관계를 그래프로 표현하면 다음과 같다.

![img](https://wikidocs.net/images/page/21670/%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%99%80%EC%BD%94%EC%8A%A4%ED%8A%B8.PNG)

기울기 W가 무한대로 커지면 커질 수록 cost의 값 또한 무한대로 커지고, 반대로 기울기 W가 무한대로 작아져도 cost의 값은 무한대로 커진다.
위의 그래프에서 cost가 가장 작을 때는 볼록한 부분의 맨 아래 부분이다.
기계가 해야할 일은 cost가 가장 최소값을 가지게 하는 W를 찾는 일이므로, 볼록한 부분의 맨 아래 부분의 W의 값을 찾아야 한다.

![img](https://wikidocs.net/images/page/21670/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95.PNG)

기계는 임의의 랜덤값 W값을 정한 뒤에, 맨 아래의 볼록한 부분을 향해 점차 W의 값을 수정해 나간다.
위의 그림은 W값이 점차 수정되는 과정을 보여준다.
그리고 이를 가능하게 하는 것이 경사 하강법이다.
이를 이해하기 위해서는 고등학교 수학 과정인 미분을 이해해야 한다.
경사 하강법은 미분을 배우게 되면서 가장 처음 배우게 되는 개념인 한 점에서의 순간 변화율 또는 다른 표현으로는 접선에서의 기울기릐 개념을 사용한다.

![img](https://wikidocs.net/images/page/21670/%EC%A0%91%EC%84%A0%EC%9D%98%EA%B8%B0%EC%9A%B8%EA%B8%B01.PNG)

위의 그림에서 초록색 선은 W가 임의 의 값을 가지게 되는 네 가지의 경우에 대해서, 그래프 상으로 접선의 기울기를 보여준다.
주목할 것은 맨 아래의 볼록한 부분으로 갈 수록 접선의 기울기가 점차 작아진다는 것이다.
그리고 맨 아래의 볼록한 부분에서는 결국 접선의 기울기가 0이 된다.
그래프 상으로는 초록색 화살표가 수평이 되는 지점이다.

즉, cost가 최소화 되는 지점은 접선의 기울기가 0이 되는 지점이며, 또한 미분값이 0이 되는 지점이다.
경사 하강법의 아이디어는 비용 함수를 미분하여 현재 W에서의 접선의 기울기를 구하고, 접선의 기울기가 낮은 방향으로 W의 값을 변경하고 다시 미분하고 이 과정을 접선의 기울기가 0인 곳을 향해 W의 값을 변경하는 작업을 반복하는 것에 있다.

비용 함수는 아래와 같다.
$$
cost(W, b) = \frac{1}{n} \sum_{i=1}^{n} \left[y^{(i)} - H(x^{(i)})\right]^2
$$
이제 비용을 최소화하는 W를 구하기 위해 W를 업데이트하는 식은 다음과 같다.
이를 접선의 기울기가 0이 될 때까지 반복한다.
$$
W := W - α\frac{∂}{∂W}cost(W)
$$
위의 식은 현재 W에서의 접선의 기울기와 α와 곱한 값으 현재 W에서 빼서 새로운 W의 값으로 한다는 것을 의미한다.
α는 여기서 학습률(learning rate)이라고 하는데, 우선 α는 생각하지 않고 현재 W에서의 접선의 기울기를 빼는 행위가 어떤 의미가 있는지 알아보자.

![img](https://wikidocs.net/images/page/21670/%EB%AF%B8%EB%B6%84.PNG)

위의 그림은 접선의 기울기가 음수일 때, 0일 떄, 양수일 때의 경우를 보여준다.
접선의 기울기가 음수일 때는 위의 수식이 아래와 같이 표현할 수 있다.
$$
W := W - α(음수 기울기) = W + α(양수 기울기)
$$
즉, 기울기가 음수면 W의 값이 증가하게 되는데 이는 결과적으로 접선의 기울기가 0인 방향으로 W의 값이 조정된다.
만약, 접선의 기울기가 양수라면 위의 수식은 아래와 같이 표현할 수 있다.
$$
W := W - α(양수 기울기)
$$
기울기가 양수면 W의 값이 감소하게 되는데 이는 결과적으로 기울기가 0인 방향으로 W의 값이 조정된다.
결국 아래의 수식은 접선의 기울기가 음수거나, 양수일 때 모두 접선의 기울기가 0인 방향으로 W의 값을 조정한다.
$$
W := W - α\frac{∂}{∂W}cost(W)
$$
그렇다면 여기서 학습률이라고 말하는 α는 어떤 의미를 가질까.
학습률 α는 W의 값을 변경할 때, 얼마나 크게 변경할지를 결정한다.
또는 W를 그래프의 한 점으로 보고 접선의 기울기가 0일 때까지 경사를 따라 내려간다는 관점에서는 얼마나 큰 폭으로 이동할지를 결정한다.
직관적을호 생각하기에 학습률 α의 값을 무작정 크게 하면 접선의 기울기가 최소값이 되는 W를 빠르게 찾을 수 있을 것 같지만 그렇지 않다.

![img](https://wikidocs.net/images/page/21670/%EA%B8%B0%EC%9A%B8%EA%B8%B0%EB%B0%9C%EC%82%B0.PNG)

위의 그림은 학습률 α가 지나치게 높은 값을 가질 때, 접선의 기울기가 0이 되는 W를 찾아가는 것이 아니라 W의 값이 발산하는 상황을 보여준다.
반대로 학습률 α가 지나치게 낮은 값을 가지면 학습 속도 느려지므로 적당한 α의 값을 찾아내는 것도 중요하다.
지금까지는 b는 배제시키고 최적의 W를 찾아내는 것에만 초점을 맞추어 경사 하강법의 원리에 대해서 배웠는데, 실제 경사 하강법은 W와 b에 대해서 동시에 경사 하강법을 수행하면서 최적의 W와 b의 값을 찾아간다.

정리하자면 가설, 비용 함수, 옵티마이저는 ML분야에서 사용되는 포괄적 개념이다.
풀고자하는 각 문제에 따라 가설, 비용 함수, 옵티마이저는 전부 다를 수 있으며 선형 회귀에 가장 적합한 비용 함수와 옵티마이저가 알려져 있는데 MSE와 경사 하강법이 각각 이에 해당된다.

---

### 3.5 케라스로 구현하는 선형 회귀

간단하게 케라스를 이용해서 선형 회귀를 구현해보도록 하자.
우선 케라스로 모델을 만드는 기본적인 형식은 다음과 같다.

```python
model = keras.models.Sequential()
model.add(keras.layers.Dense(1,input_dim=1))
```

Sequential로 model이라는 이름의 모델을 만들고, 그리고 add를 통해 필요한 사항들을 추가해 간다.
첫번째 인자인 1은 출력의 차원을 의미하며, 두번째 인자인 input_dim은 입력의 차원을 정의하는데 이번 실습과 같이 1개의 실수 x를 가지고 하는 1개의 실수 y를 예측하는 단순 선형 회귀를 구현하는 경우에는 각각 1의 값을 가진다.
이제 직접 실습을 진행해보자.

```python
from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트
from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트
from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트
import numpy as np # Numpy를 임포트

X=np.array([1,2,3,4,5,6,7,8,9]) # 공부하는 시간
y=np.array([11,22,33,44,53,66,77,87,95]) # 각 공부하는 시간에 맵핑되는 성적

model=Sequential()
model.add(Dense(1, input_dim=1, activation='linear'))
sgd=optimizers.SGD(lr=0.01)
# 학습률(learning rate, lr)은 0.01로 합니다.
model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])
# sgd는 경사 하강법을 의미.
# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.
model.fit(X,y, batch_size=1, epochs=300, shuffle=False)
# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다.
```

위의 코드는 간단하지만, 지금까지 배운 것들이 집대성 된 코드이다.
우선 공부한 시간을 x, 각 공부한 시간에 따른 성적을 y라고 해보자.
activation은 어떤 함수를 사용할 것인지를 의미하는데 선형 회귀를 사용할 경우에는 linear라고 기재한다.

옵티마이저로는 경사 하강법의 일종인 확률적 경사 하강법을 사용하였으며, 학습률은 0.01로 정하였다.
손실 함수로는 평균 제곱 오차를 사용한다.
그리고 전체 데이터에 대한 훈련 횟수는 300으로 한다.

```
Epoch 1/300
9/9 [==============================] - 0s 37ms/step - loss: 294.9226 - mean_squared_error: 294.9226
... 중략 ...
Epoch 167/300
9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mean_squared_error: 2.1460
... 중략 ...
Epoch 300/300
9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mean_squared_error: 2.1460
```

전체 데이터에 대한 훈련 횟수는 300으로 하였지만, 어느 순간 오차가 더 이상 줄어들지 않는데 이는 오차를 최소화하는 가중치 W와 b를 찾았기 때문으로 추정이 가능하다.
이제 최종적으로 선택된 오차를 최소화하는 직선을 그래프로 그려보자.

```python
%matplotlib inline
import matplotlib.pyplot as plt
plt.plot(X, model.predict(X), 'b', X,y, 'k.')
```

![img](https://wikidocs.net/images/page/21670/%EC%A7%81%EC%84%A0.png)

위의 그래프에서 각 점은 우리가 실제 주었던 실제값에 해당되며, 직선은 실제값으로부터 오차를 최소화하는 W와 b의 값을 가지는 직선이다.
이제 이 직선을 통해 9시간 30분을 공부하였을 때의 시험 성적을 예측하게 해보자.
model.predict()은 학습이 완료된 모델이 입력된 데이터에 대해서 어떤 값을 예측하는지를 보여준다.

```python
print(model.predict([9.5]))
```

```python
[[98.556465]]
```

시간 30분을 공부하면 약 98.5점을 얻는다고 예측하고 있다.

---

### 4. 로지스틱(Logistic Regression) - 이진 분류

일상 속 풀고자하는 많은 문제 중에서 두 개의 선택지 중에서 고르는 문제가 많다.
예를 들어 시험을 봤는데 이 시험 점수가 합격인지가 궁금할 수도 있고, 어떤 메일을 받았을 때 이게 정상 메일인지 스팸 메일인지를 분류하는 문제도 그렇다.
이렇게 둘 중 하나를 결정하는 문제를 이진 분류(Binary Classification)이라고 한다.
그리고 이런 문제를 풀기 위한 대표적인 알고리즘으로 로지스틱 회귀(Logistic Regression)이 있다.

---

### 4.1 이진 분류(Binary Classification)

선형 회귀에서 공부 시간과 성적 간의 관계를 직선의 방정식으로 표현한다는 가설 하에, 주어진 데이터로부터 가중치 W와 편향 b를 찾아 데이터를 가장 잘 표현하는 직선을 찾았다.
그런데 이번에 배울 둘 중 하나의 선택지 중에서 정답을 고르는 이진 분류 문제는 직선으로 표현하는 것이 적절하지 않다.

학생들이 시험 성적에 따라서 합격, 불합격이 기재된 데이터가 있다고 가정해보자.
시험 성적이 x라면, 합불 결과는 y이다.
이 시험의 커트라인은 공개되지 않았는데 이 데이터로부터 특정 점수를 얻었을 때의 합격, 불합격 여부를 판정하는 모델을 만들고자 한다.

| score(x) | result(y) |
| :------: | :-------: |
|    45    |  불합격   |
|    50    |  불합격   |
|    55    |  불합격   |
|    60    |   합격    |
|    65    |   합격    |
|    70    |   합격    |

위의 데이터에서 합격을 1, 불합격을 0이라고 하였을 때 그래프를 그려보면 아래와 같다.

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG)

이러한 점들을 표현하는 그래프는 알파벳의 S자 형태로 표현된다.
이러한 x와 y의 관계를 표현하기 위해서는 직선을 표현하는 함수가 아니라 S자 형태로 표현할 수 있는 함수가 필요하다.
직선을 사용할 경우 보통 분류 작업이 제대로 동작하지 않는다.

또한 이번 예제의 경우 실제값 y가 0 또는 1이라는 두 가지 값밖에 가지지 않으므로, 이 문제를 풀기 위해서는 예측값이 0과 1사이의 값을 가지도록 하는 것이 보편적이다.
0과 1사이의 값을 확률로 해석하면 문제를 풀기가 훨씬 용이해진다.
최종 예측값이 0.5보다 작으면 0으로 예측했다고 판단하고, 0.5보다 크면 1로 예측했다고 판단할 수 있기 때문이다.
하지만 선형 회귀의 경우 y값이 음의 무한대로부터 양의 무한대와 같은 큰 수들도 가질 수 있는데 이는 분류 문제에 적합하지 않은 두번째 이유이다.

0과 1사이의 값을 가지면서, S자 형태로 그려지는 조건을 충족하는 함수가 있다.
바로 시그모이드 함수(Sigmoid function)이다.

---

### 4.2 시그모이드 함수(Sigmoid function)

이 문제에서 사용하게 될 시그모이드 함수의 방정식은 아래와 같다.
종종 σ로 축약해서 표현하기도 한다.
이는 위의 문제를 풀기 위한 가설식이기도 한다.
$$
H(X) = \frac{1}{1 + e^{-(Wx + b)}} = sigmoid(Wx + b) = σ(Wx + b)
$$
여기서 e(e=2.718281...)는 자연 상수이다.
여기서 구해야 할 것은 여전히 주어진 데이터에 가장 적합한 가중치 W와 편향 b이다.
인공지능 알고리즘이 하는 것은 결국 주어진 데이터에 적합한 가중치 W와 b를 구하는 것이다.

시그모이드 함수는 파이썬의 Matplotlib을 통해서 그래프로 표현해보자.
우선 필요한 도구들을 임포트한다.

```python
%matplotlib inline
import numpy as np # 넘파이 사용
import matplotlib.pyplot as plt # 맷플롯립 사용
```

아래의 그래프는 W는 1, b는 0임을 가정한 그래프이다.

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))
x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)

plt.plot(x, y, 'g')
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%EA%B7%B8%EB%9E%98%ED%94%84.png)

위의 그래프를 통해 알 수 있는 것은 시그모이드 함수는 출력값을 0과 1사이의 값으로 조정하여 반환한다.
마치 S자의 모양을 연상시킨다.
x가 0일 때, 0.5의 값을 가진다.
x가 증가하면 1에 수렴한다.
여기서 구해야 할 가중치 W와 편향 b가 어떤 의미를 가지는지 한 번 그래프를 통해 알아보자.
우선 W의 값을 변화키고 이에 따른 그래프를 확인해보자.

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))
x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(0.5*x)
y2 = sigmoid(x)
y3 = sigmoid(2*x)

plt.plot(x, y1, 'r', linestyle='--') # W의 값이 0.5일때
plt.plot(x, y2, 'g') # W의 값이 1일때
plt.plot(x, y3, 'b', linestyle='--') # W의 값이 2일때
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%ED%95%A8%EC%88%98%EC%9D%98%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%9D%98%EB%B3%80%ED%99%94.png)

위의 그래프는 W의 값이 0.5일 때 빨간색 선, W의 ㄱ밧이 1일 때는 초록색선, W의 값이 2일 때 파란색선이 나오도록 했다.
자세히 보면 W의 값에 따라 그래프의 경사도가 변하는 것을 볼 수 있다.
앞서 선형 회귀에서 가중치 W는 직선의 기굴기를 의미했지만, 여기서는 그래프의 경사도를 결정한다.
W의 값이 커지면 경사가 커지고 W의 값이 작아지면 경사가 작아진다.

이제 b의 값에 따라서 그래프가 어떻게 변하는지 확인해보도록 하자.

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))
x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(x+0.5)
y2 = sigmoid(x+1)
y3 = sigmoid(x+1.5)

plt.plot(x, y1, 'r', linestyle='--') # x + 0.5
plt.plot(x, y2, 'g') # x + 1
plt.plot(x, y3, 'b', linestyle='--') # x + 1.5
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/b%EC%9D%98%EC%9D%B4%EB%8F%99.png)

위의 그래프는 b의 값에 따라서 그래프가 이동하는 것을 보여준다.
지금까지 시그모이드 함수에 대해서 정리해보았다.
시그모이드 함수는 입력값이 커지면 1에 수렴하고, 입력값이 작아지면 0에 수렴한다.
0부터 1까지의 값을 가지는데 출력값이 0.5이상이면 1(True), 0.5이하면 0(False)로 만들면 이진 분류 문제로 사용할 수 있다.
이를 확률이라고 생각하면 해당 범주에 속할 확률이 50%가 넘으면, 해당 범주라고 판단하고 50%보다 낮으면 아니라고 판단한다고 볼 수 있다.

---

### 4.3 비용 함수(Cost function)

로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 W를 찾아내지만, 비용 함수로는 평균 제곱 오차를 사용하지 않는다.
그 이유는 시그모이드 함수에 비용 함수를 평균 제곱 오차로 하여 그래프를 그리면 다음과 비슷한 형태가 되기 때문이다.

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%BB%AC%EB%AF%B8%EB%8B%88%EB%A9%88.PNG)

로지스틱 회귀에서 평균 제곱 오차를 비용 함수로 사용하면, 경사 하강법을 사용하였을 때 자칫 잘못하면 찾고자 하는 최소값이 아닌 잘못된 최소값에 빠진다.
이를 전체 함수에 걸쳐 최소값인 글로벌 미니멈(Global Minimum)이 아닌 특정 구역에서의 최소값인 로컬 미니멈(Local Minimum)에 도달했다고 한다.
이는 cost가 최소가 되는 가중치 W를 찾는다는 비용 함수의 목적에 맞지 않는다. 

그렇다면 가중차 W를 최소로 만드는 새로운 비용 함수를 찾아야 한다.
가중치를 최소화하는 아래의 어떤 함수를 목적 함수라고 한다.
비용 함수와 목적 함수를 최적의 가중치를 찾기 위해 함수의 값을 최소화하는 함수라는 의미에서 같은 의미의 용어로 사용한다.
J는 목적 함수를 의미한다.
$$
J(W) = \frac{1}{n} \sum_{i=1}^{n} f\left(H(x^{(i)}), y^{(i)})\right)
$$
위의 식은 완성되지 않았다.
위의 식에서 샘플 데이터의 개수가 n개이고, 어떤 함수가 f가 실제값 yi와 예측값 H(xi)의 오차를 나타내는 함수락 할 때, 여기서 새로운 함수 f를 어떻게 정의하느냐에 따라서 가중치를 최소화하는 적절한 목적 함수가 완성된다.
목적 함수는 전체 데이터에 대해서 어떤 함수 f의 값의 평균을 계산하고 있다.
적절한 가중치를 찾기 위해서는 결과적으로 실제값과 예측값에 대한 오차를 줄어야 하므로 여기서 이 f는 비용 함수(cost function)라고 하자.

시그모이드 함수는 0과 1사이의 y값을 반환한다.
이는 실제값이 0일 때 y값이 1에 가까웢면 오차가 커지며 실제값이 1일 때 y값이 0에 가까워지면 오차가 커짐을 의미한다.
그리고 이를 반영할 수 있는 함수는 로그 함수를 통해 표현이 가능하다.
$$
\text{if } y=1 → \text{cost}\left( H(x), y \right) = -\log(H(x))
$$

$$
\text{if } y=0 → \text{cost}\left( H(x), y \right) = -\log(1-H(x))
$$

y의 실제값이 1일 때 −logH(x) 그래프를 사용하고 y의 실제값이 0일 때 −log(1−H(X)) 그래프를 사용해야 한다.
위의 두 식을 그래프 상으로 표현하면 아래와 같다.

![img](https://wikidocs.net/images/page/22881/%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98.PNG)

실제값이 1일 때의 그래프를 파란색 선으로 표현하였으며, 실제값이 0일 때의 그래프를 빨간색 선으로 표현했다.
위의 그래프를 간략히 설명하면, 실제값이 1일 때, 예측값인 H(X)의 값이 1이면 오차가 0이므로 당연히 cost는 0이된다.
반면 실제값이 1일 때, H(X)가 0으로 수렴하면 cost는 무한대로 발산한다.
실제값이 0인 경우는 그 반대로 이해하면 된다.
이는 다음과 같이 하나의 식으로 표현할 수 있다.
$$
\text{cost}\left( H(x), y \right) = -[ylogH(x) + (1-y)log(1-H(x))]
$$
자세히 보면 y와 (1 - y)가 식 중간에 들어갔고, 두 개의 식을 -로 묶은 것 외에는 기존의 두 식이 들어가 있는 것을 볼 수 있다.
y가 0이면 ylogH(X)가 없어지고, y가 1이면 (1−y)log(1−H(X))가 없어지는데 이는 각각 yy가 1일 때와 yy가 0일 때의 앞서 본 식과 동일하다.

결과적으로 로지스틱 회귀의 목적 함수는 아래와 같다.
$$
J(W) = -\frac{1}{n} \sum_{i=1}^{n} [y^{(i)}logH(x^{(i)}) + (1-y^{(i)})log(1-H(x^{(i)}))]
$$
이때 로지스틱 회귀에서 찾아낸 비용 함수를 크로스 엔트로피(Cross Entropy)함수라고 한다.
즉,결론적으로 로지스틱 회귀는 비용 함수로 크로스 엔트로피 함수를 사용하며, 가중치를 찾기 위해서 크로스 엔트로피  함수의 평균을 취한 함수를 사용한다.
크로스 엔트로피 함수는 소프트맥스 회귀의 비용 함수이기도 하므로 후에 언급한다.

---

### 4.4 케라스로 구현하는 로지스틱 회귀

```python
import numpy as np
from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트
from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트
from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트

X=np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])
y=np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) #숫자 10부터 1

model=Sequential()
model.add(Dense(1, input_dim=1, activation='sigmoid'))
sgd=optimizers.SGD(lr=0.01)
model.compile(optimizer=sgd ,loss='binary_crossentropy',metrics=['binary_accuracy'])
# 옵티마이저는 경사하강법 sgd를 사용합니다.
# 손실 함수(Loss function)는 binary_crossentropy(이진 크로스 엔트로피)를 사용합니다.
model.fit(X,y, batch_size=1, epochs=200, shuffle=False)
# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다.
```

임의의 숫자들의 나열을 X라고 하였을 때, 숫자 10 이상인 경우에는 1, 미만인 경우에는 0을 부여한 레이블 데이터를 y라고 하자.
이번 데이터는 앞서 배운 단순 선형 회귀때와 마찬가지로 1개의 실수인 X로부터 1개의 실수인 y를 예측하는 맵핑 관계를 가지므로 각각 1을 기재한다.
또한 시그모이드 함수를 사용할 것이므로 activation에 sigmoid를 기재해준다.

옵티마이저로는 경사 하강법의 일종의 확률적 경사 하강법을 사용하였으며, 손실 함수로는 크로스 엔트로피 함수를 사용한다.
이진 분류 문제에 크로스 엔트로피 함수를 사용할 경우에는 binary_crossentropy를 기재해주면 된다.
전체 데이터에 대한 훈련 횟수는 200으로 한다.

```python
Epoch 1/200
13/13 [==============================] - 1s 65ms/step - loss: 0.3375 - binary_accuracy: 0.8462
... 중략 ...
Epoch 192/200
13/13 [==============================] - 0s 1ms/step - loss: 0.0898 - binary_accuracy: 1.0000
... 중략 ...
Epoch 200/200
13/13 [==============================] - 0s 1ms/step - loss: 0.0883 - binary_accuracy: 1.0000
```

총 200회에 걸쳐 전체 데이터에 대한 오차를 최소화하는 W와 b를 찾아내는 작업을 한다.
약 190회부터 정확도가 100%가 나오기 시작한다.
실제값과 오차를 최소화하는 W와 b의 값을 가진 시그모이드 함수 그래프를 그려보자.

```python
%matplotlib inline
import matplotlib.pyplot as plt
plt.plot(X, model.predict(X), 'b', X,y, 'k.')
```

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.png)

X값이 5와 10사이의 어떤 값일 때 y값이 0.5가 넘기 시작하는 것처럼 보인다.
정확도가 100%가 나왔었기 때문에 적어도 X값이 5일 때는 y값이 0.5보다 작고, X값이 10일 때는 y값이 0.5를 넘을 것이다.
이제 X값이 5보다 작은 값일 때와 X값이 10보다 클 때에 대해서 y값을 출력해보자.

```python
print(model.predict([1, 2, 3, 4, 4.5]))
print(model.predict([11, 21, 31, 41, 500]))
```

```python
[[0.21071826]
 [0.26909265]
 [0.33673897]
 [0.41180944]
 [0.45120454]]
[[0.86910886]
 [0.99398106]
 [0.99975663]
 [0.9999902 ]
 [1.        ]]
```

X값이 5보다 작을 때는 0.5보다 작은 값을, X값이 10보다 클 때는 0.5보다 큰 값을 출력하는 것을 볼 수 있다.